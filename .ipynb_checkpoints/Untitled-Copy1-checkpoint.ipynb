{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b24411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9e05a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_df=pd.read_excel(\"Stocks.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b7ae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# unique_counts = stock_df[\"Count\"].unique()\n",
    "# unique_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4abf1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # List of strings\n",
    "# data = ['8/1 Bleached ', '8/1 Hessain', '10.4/3 vot', '14/2  Hessian', '16/2 Ply', '16/3 Green', '18/2 Ply', '20/2 Black', '20/2 Skg', '20/3 Skg', '21/1 Beached', '21/3 CB Bleached', '26/1  Black', '8/1 Bleached', '8/1 Bleach ', '10/2  Hessian', '14/3 100,200gm', '14/5 800gm', '14/5 4kg spool', '14/3 160 grams Spool', '14/3 250 grams Spool', '14/3 730g bleached', '14/3 830 grams Spool', '14/3 90gVot', '16/2 Bleach Vot', '16/2 CRM/CRT', '18/1 Ply', '19.35/3 Orange', '24/1 Ply N', '26/1 Ply', '28/5 Hanks', '28/1 skg  Spool', '40/1 Ply-J', '36/3 Natural', '24/1 CRM/CRT', '21/1 Heavy', '16/2 Bleached', '20/1 Ply', '24/1 Ply', '8/1 Bleached Vot', '14/2  Hessian Mini Spool', '16/2 Pink Vot', '16/2 Heavy', '16/2 Heavy Vot', 'Jute Fiber Bleached', '10/2 Ply Vot  Hessian', '16/2 Ply Crt', '20/2 Heavy', '16/2 Heavy vot', '16/1 CRT', '12/2 Vot 420gm', '14/2  Hessian ', '14/2  Hess Mini Spool', '18/2 CRX', '18/2 Ply ', '19.35/4 Vot', '19.35/5 Vot', '32/5 900gm spool', '16/2 Heavy ', '18/2 CRT', '6.9/1 Coated', '8/5 White', '10/2', '10/2 Vot PVA', '11.5/3 Ball', '11.62/2 mix.6 colour', '14/1 Ply', '14/3 Vot', '14/3 6 items colour', '14/5 Vot  ball', '14.5/6 2.50kg spool', '14/2', '16/1 ply', '16/2', '18/2 ply', '18/1 ply', '20/6 Skg(Hank)', '20/5 Skg(Hank)', '21/1 vot', '20.74/4 Vot', '26/1', '28/1 cop(Lot-36)', '28/5 Ply', '30/1 Ply', '32/5 Vot(Ball)', '36/1 White', '40/1 ply', '60/1 ply', '72/2,3,4,6 vot 2.50kg spool', '90/2 Sack', '90/1 Ply', '120/1 Ply', '150/1 ply', '300/1 ply', '400/1 ply', '90/1 ply', '200/1 Ply', '10/2 Hassian', '26/1 CRT', '28/5 Ply vot', '180/1 ply', '90/2 Sack vot', \"14/1 Ply(6*8)'(10*8\", '20/2 Skg Vot', '21/1 vot hassian', '20/2 seck VOT', '20/2 seck Vot', '20/5 hass. Vot', '28/1 cop(Lot-36,37)', '11.5/3 Ball 100gm,400gm', '16/5 Ball 200gm', '28/1 cop(Lot-38)', '250/1 ply', '70/3 vot', '12/2 ply CRT', '16/5 Ball 400gm', '90/1 ply (10*10)', '11.5/3 Ball 100gm', '11.5/3 Ball 400gm', '14/1 ply pva coated', '8/3 PVA coated vot', '14/3 ball 850g ', '14/3,5,6ball 850g ', '28/1 cop(Lot-39)', '20/1 ply CRT']\n",
    "\n",
    "# # Split each string into two parts and create a DataFrame\n",
    "# df = pd.DataFrame([s.split(maxsplit=1) for s in unique_counts], columns=['First_Part', 'Second_Part'])\n",
    "\n",
    "# print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8aa2acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df=pd.read_excel(\"production.xlsx\")\n",
    "\n",
    "# # df_copy=pd.read_excel(\"production - Copy.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb559127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if df[\"Factory\"]==\"JJMLN\":\n",
    "#     print(df[\"count\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58328626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Filter rows where \"Factory\" is equal to \"JJMLN\"\n",
    "# jjmln_rows = df[df[\"Factory\"] == \"JJMLN\"]\n",
    "\n",
    "# # Extract the unique values of \"count\" column\n",
    "# unique_counts = jjmln_rows[\"count\"]\n",
    "\n",
    "# # Extract the corresponding values of \"Conversion factor\" column\n",
    "# conversion_factors = jjmln_rows[\"Conversion factor\"]\n",
    "\n",
    "# # Create a new DataFrame with the extracted data\n",
    "# data = {\n",
    "#     \"Count\": unique_counts,\n",
    "#     \"Conversion Factor\": conversion_factors\n",
    "# }\n",
    "# new_df = pd.DataFrame(data)\n",
    "\n",
    "# # Write the DataFrame to a new Excel file\n",
    "# output_file_path = \"jjmln_counts_conversion_factors.xlsx\"\n",
    "# new_df.to_excel(output_file_path, index=False)\n",
    "\n",
    "# print(\"Data saved to\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0265d7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Read the Excel file\n",
    "# excel_file_path = \"path/to/production - Copy.xlsx\"\n",
    "# daily_production_df = pd.read_excel(excel_file_path, sheet_name=\"Daily Production\")\n",
    "\n",
    "# # Find rows where \"Conversion factor\" column is empty\n",
    "# empty_conversion_factor_rows = daily_production_df[daily_production_df[\"Conversion factor\"].isnull()]\n",
    "\n",
    "# # Assign provided data to the empty \"Conversion factor\" rows\n",
    "# empty_conversion_factor_rows[\"Conversion factor\"] = provided_data\n",
    "\n",
    "# # Write the updated DataFrame back to the Excel file\n",
    "# with pd.ExcelWriter(excel_file_path, mode='a', engine=\"openpyxl\") as writer:\n",
    "#     empty_conversion_factor_rows.to_excel(writer, sheet_name=\"Daily Production\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f11243a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Provided data\n",
    "# provided_data = [\n",
    "#     0.344523414, 0.615157241, 0.615157241, 2.728135932, 0.513951956, 0.766622376, \n",
    "#     None, 0.629156804, 0.909390297, 2.728135932, 0.48813487, 0.766622376, 1.952539482, \n",
    "#     1, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.48813487, \n",
    "#     0.719418115, None, 2.728135932, None, None, 0.909390297, 2.728135932, 0.766622376, \n",
    "#     0.626092864, 0.626092864, None, 2.728135932, 0.909390297, 0.626092864, 0.626092864, \n",
    "#     0.719418115, 1.573757041, 0.626092864, 1, 0.909390297, 0.719418115, 2.728135932, \n",
    "#     None, None, 0.909390297, 3.528414458, 1, 1.952539482, 0.626092864, None, None, \n",
    "#     2.728135932, 2.728135932, None, None, None, None, None, 0.626092864, 0.626092864, \n",
    "#     0.626092864, 0.626092864, 0.626092864, None, 0.629156804, 0.719418115, None, \n",
    "#     0.766622376, 0.626092864, 0.626092864, 0.719418115, 1.573757041, 1.573757041, \n",
    "#     None, None, 2.728135932, 1, 0.909390297, 0.909390297, 2.728135932, 1.952539482, \n",
    "#     0.766622376, 0.766622376, 0.766622376, None, None, 0.626092864, 0.626092864, \n",
    "#     0.626092864, 0.626092864, None, 2.728135932, 0.719418115, None, None, None, \n",
    "#     0.909390297, None, 0.909390297, 0.626092864, 0.48813487, 0.48813487, 1.234101382, \n",
    "#     1, None, None, None, None, None, None, None, None, 2.728135932, 1.234101382, \n",
    "#     1.234101382, 1.234101382, 0.719418115, None, 0.766622376, 2.728135932, 0.626092864, \n",
    "#     1.952539482, 2.728135932, 0.626092864, 0.626092864, 0.909390297, 0.909390297, \n",
    "#     0.909390297, None, None, None, None, 0.48813487, 0.766622376, None, 0.626092864, \n",
    "#     0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, \n",
    "#     0.626092864, 0.626092864, 2.728135932, 0.719418115, 0.719418115, 0.766622376, \n",
    "#     1.952539482, 1.952539482, 1.952539482, 1.952539482, None, 1.952539482, None, \n",
    "#     1.952539482, None, 0.626092864, None, 0.909390297, 0.629156804, 0.629156804, \n",
    "#     0.629156804, 1, 1, 0.719418115, 0.719418115, 0.766622376, 0.766622376, 2.728135932, \n",
    "#     2.728135932, 2.728135932, 2.728135932, 1.234101382, 1.234101382, 1.234101382, \n",
    "#     1.234101382, 2.728135932, 0.766622376, None, None, 1, 1, 1, 1, 0.626092864, \n",
    "#     0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.719418115, 2.728135932, \n",
    "#     1.952539482, 1.952539482, 0.766622376, 0.766622376, 0.766622376, 0.909390297, \n",
    "#     None, 0.629156804, 0.629156804, 2.728135932, 0.719418115, 1.573757041, 1.573757041, \n",
    "#     1, 1, None, None, None, None, 2.728135932, 1.234101382, 0.48813487, 2.728135932, \n",
    "#     2.728135932, 0.626092864, 0.626092864, 0.626092864, None, 1.952539482, 1.952539482, \n",
    "#     None, 1.952539482, 0.629156804, 2.728135932, None, 1.234101382, 1, 0.909390297, \n",
    "#     0.909390297, 0.909390297, 2.728135932, None, None, 1.952539482, 2.728135932, \n",
    "#     None, None, None, None, 1.234101382, 1.234101382, 1.234101382, 1.234101382, \n",
    "#     2.728135932, 2.728135932, 2.728135932, 2.728135932, 2.728135932, 0.719418115, \n",
    "#     0.719418115, 0.909390297, 2.728135932, 1, None, 1.952539482, 0.766622376, \n",
    "#     0.766622376, 0.629156804, 2.728135932, 1, 1, None, None, 0.719418115, 0.626092864, \n",
    "#     0.909390297, 0.719418115, 0.719418115, 0.719418115, 1, 1, 0.629156804, 0.909390297, \n",
    "#     2.728135932, 2.728135932, 0.909390297, 0.909390297, 0.909390297, 0.909390297, \n",
    "#     0.909390297, 1.952539482, 1.952539482, None, 0.909390297, 2.728135932, 1.573757041, \n",
    "#     1.573757041, 1.234101382, 2.728135932, 0.629156804, 0.766622376, 0.766622376, \n",
    "#     0.909390297, 0.766622376, 2.728135932, None, 0.909390297, 0.909390297, \n",
    "#     0.909390297, 0.909390297, None, None, None, None, 1.952539482, None, None, \n",
    "#     2.728135932, None, 2.728135932, None, 1.952539482, None, 2.728135932, None, \n",
    "#     None, None, 2.728135932, 2.728135932, None, 2.728135932, None, None, None, \n",
    "#     0.766622376, 0.766622376, 0.48813487, None, 0.626092864, 1.952539482, 1, \n",
    "#     0.719418115, 0.719418115, 1.234101382, 1.234101382, 0.48813487, 0.48813487, \n",
    "#     None, None, None, 2.728135932, 2.728135932, 0.909390297, None, 2.728135932, \n",
    "#     1, None, 0.629156804, 0.629156804, 0.629156804, 0.629156804, 1.952539482, \n",
    "#     0.766622376, 0.766622376, 0.766622376, None, 0.909390297, 0.909390297, 1, \n",
    "#     1.573757041, 2.728135932, 2.728135932, 1.952539482, 1.952539482, 0.719418115, \n",
    "#     1, 0.909390297, 0.909390297, 0.909390297, None, 2.728135932, None, None, \n",
    "#     None, None, None, 2.728135932, 2.728135932, 0.909390297, 0.909390297, \n",
    "#     1.234101382, 1, 1, 1, 1, 1, 1, 0.626092864, 0.626092864, 0.626092864, \n",
    "#     0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, \n",
    "#     0.719418115, 0.719418115, 0.719418115, 2.728135932, None, 0.629156804, \n",
    "#     0.909390297, 0.766622376, 1.573757041, 1, None, None, 0.909390297, 0.909390297, \n",
    "#     0.909390297, 0.909390297, 0.909390297, 0.909390297, 2.728135932, None, \n",
    "#     2.728135932, None, 2.728135932, 2.728135932, 2.728135932, 2.728135932, \n",
    "#     2.728135932, None, None, 1, 0.909390297, 0.909390297, 0.629156804, \n",
    "#     1.234101382, 2.728135932, 0.909390297, 1, 1, None, 1.952539482, 1.952539482, \n",
    "#     1.952539482, 1.952539482, 1.952539482, 1.952539482, 1.952539482, None, \n",
    "#     0.629156804, 1, 1, None, None, None, 2.728135932, 2.728135932, 2.728135932, \n",
    "#     2.728135932, 2.728135932, 2.728135932, 2.728135932, 2.728135932, 2.728135932, \n",
    "#     2.728135932, 2.728135932, 0.719418115, 0.48813487, None, None, 0.629156804, \n",
    "#     0.629156804, 0.719418115, 1, None, None, 0.629156804, 0.629156804, 0.719418115, \n",
    "#     None, None, None, None, 2.728135932, 0.909390297, 0.909390297, 0.909390297, \n",
    "#     0.909390297, 0.909390297, 0.909390297, 0.909390297, 0.909390297, None, \n",
    "#     1.234101382, 2.728135932, 1.952539482, 2.728135932, None, 1.952539482, 1, 1, \n",
    "#     1, 1, 1, None, None, 0.719418115, None, None, None, 2.728135932, 2.728135932, \n",
    "#     1.952539482, 0.719418115, 0.909390297, 2.728135932, 2.728135932, 2.728135932, \n",
    "#     2.728135932, 0.629156804, 0.629156804, 0.629156804, 0.629156804, 0.629156804, \n",
    "#     0.629156804, 0.626092864, None, 2.728135932, 0.766622376, None, 2.728135932, \n",
    "#     0.909390297, 1, 2.728135932, 0.629156804, 0.629156804, None, 1.234101382, \n",
    "#     0.909390297, 0.909390297, 1.952539482, 1.952539482, 0.626092864, 0.626092864, \n",
    "#     1.952539482, 0.719418115, 0.719418115, 0.719418115, 1.952539482, 0.513951956, \n",
    "#     0.766622376, 2.728135932, 0.629156804, 0.766622376, 1.234101382, 0.48813487, \n",
    "#     0.48813487, 2.728135932, 2.728135932, 0.719418115, 1, 1, 1, 1.573757041, None, \n",
    "#     None, None, None, None, None, 2.728135932, None, 2.728135932, 2.728135932, \n",
    "#     0.719418115, 2.728135932, 0.909390297, 0.909390297, 2.728135932, 2.728135932, \n",
    "#     None, None, 0.719418115, None, None, None, None, None, None, None, None, \n",
    "#     None, None, 0.766622376, None, None, 0.719418115, 2.728135932, 2.728135932, \n",
    "#     0.766622376, None, 1, 2.728135932, None, 0.909390297, 0.629156804, 2.728135932, \n",
    "#     2.728135932, 0.909390297, 2.728135932, 2.728135932, 0.909390297, None, \n",
    "#     1.234101382, 1.234101382, 0.626092864, 1, 1, 0.766622376, None, 1, 1.234101382, \n",
    "#     2.728135932, 2.728135932, 2.728135932, 2.728135932, 2.728135932, 0.629156804, \n",
    "#     0.629156804, 1, 1, 1, 1, 1.952539482, None, 0.629156804, 0.909390297, 0.909390297, \n",
    "#     2.728135932, 2.728135932, None, None, None, 1.952539482, 1.952539482, 1.952539482, \n",
    "#     0.626092864, 2.728135932, 0.766622376, 0.629156804, None, 1, None, 0.719418115, \n",
    "#     0.513951956, 1.952539482, 1.952539482, 1, 0.766622376, 0.719418115, None\n",
    "# ]\n",
    "\n",
    "# # Read the Excel file\n",
    "# excel_file_path = \"production - Copy.xlsx\"\n",
    "# daily_production_df = pd.read_excel(excel_file_path, sheet_name=\"Daily Production\")\n",
    "\n",
    "# # Find rows where \"Conversion factor\" column is empty\n",
    "# empty_conversion_factor_rows = daily_production_df[daily_production_df[\"Conversion factor\"].isnull()]\n",
    "\n",
    "# # Assign provided data to the empty \"Conversion factor\" rows\n",
    "# empty_conversion_factor_rows[\"Conversion factor\"] = provided_data\n",
    "\n",
    "# # Write the updated DataFrame back to the Excel file\n",
    "# with pd.ExcelWriter(excel_file_path, mode='a', engine=\"openpyxl\") as writer:\n",
    "#     empty_conversion_factor_rows.to_excel(writer, sheet_name=\"Daily Production\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b68ed41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# provided_data = [0.344523414, 0.615157241, 0.615157241, 2.728135932, 0.513951956, 0.766622376, None, 0.629156804, 0.909390297, 2.728135932, 0.48813487, 0.766622376, 1.952539482, 1, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.48813487, 0.719418115, None, 2.728135932, None, None, 0.909390297, 2.728135932, 0.766622376, 0.626092864, 0.626092864, None, 2.728135932, 0.909390297, 0.626092864, 0.626092864, 0.719418115, 1.573757041, 0.626092864, 1, 0.909390297, 0.719418115, 2.728135932, None, None, 0.909390297, 3.528414458, 1, 1.952539482, 0.626092864, None, None, 2.728135932, 2.728135932, None, None, None, None, None, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, None, 0.629156804, 0.719418115, None, 0.766622376, 0.626092864, 0.626092864, 0.719418115, 1.573757041, 1.573757041, None, None, 2.728135932, 1, 0.909390297, 0.909390297, 2.728135932, 1.952539482, 0.766622376, 0.766622376, 0.766622376, None, None, 0.626092864, 0.626092864, 0.626092864, 0.626092864, None, 2.728135932, 0.719418115, None, None, None, 0.909390297, None, 0.909390297, 0.626092864, 0.48813487, 0.48813487, 1.234101382, 1, None, None, None, None, None, None, None, None, 2.728135932, 1.234101382, 1.234101382, 1.234101382, 0.719418115, None, 0.766622376, 2.728135932, 0.626092864, 1.952539482, 2.728135932, 0.626092864, 0.626092864, 0.909390297, 0.909390297, 0.909390297, None, None, None, None, 0.48813487, 0.766622376, None, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 2.728135932, 0.719418115, 0.719418115, 0.766622376, 1.952539482, 1.952539482, 1.952539482, 1.952539482, None, 1.952539482, None, 1.952539482, None, 0.626092864, None, 0.909390297, 0.629156804, 0.629156804, 0.629156804, 1, 1, 0.719418115, 0.719418115, 0.766622376, 0.766622376, 2.728135932, 2.728135932, 2.728135932, 2.728135932, 1.234101382, 1.234101382, 1.234101382, 1.234101382, 2.728135932, 0.766622376, None, None, 1, 1, 1, 1, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.719418115, 2.728135932, 1.952539482, 1.952539482, 0.766622376, 0.766622376, 0.766622376, 0.909390297, None, 0.629156804, 0.629156804, 2.728135932, 0.719418115, 1.573757041, 1.573757041, 1, 1, None, None, None, None, 2.728135932, 1.234101382, 0.48813487, 2.728135932, 2.728135932, 0.626092864, 0.626092864, 0.626092864, None, 1.952539482, 1.952539482, None, 1.952539482, 0.629156804, 2.728135932, None, 1.234101382, 1, 0.909390297, 0.909390297, 0.909390297, 2.728135932, None, None, 1.952539482, 2.728135932, None, None, None, None, 1.234101382, 1.234101382, 1.234101382, 1.234101382, 2.728135932, 2.728135932, 2.728135932, 2.728135932, 2.728135932, 0.719418115, 0.719418115, 0.909390297, 2.728135932, 1, None, 1.952539482, 0.766622376, 0.766622376, 0.629156804, 2.728135932, 1, 1, None, None, 0.719418115, 0.626092864, 0.909390297, 0.719418115, 0.719418115, 0.719418115, 1, 1, 0.629156804, 0.909390297, 2.728135932, 2.728135932, 0.909390297, 0.909390297, 0.909390297, 0.909390297, 0.909390297, 1.952539482, 1.952539482, None, 0.909390297, 2.728135932, 1.573757041, 1.573757041, 1.234101382, 2.728135932, 0.629156804, 0.766622376, 0.766622376, 0.909390297, 0.766622376, 2.728135932, None, 0.909390297, 0.909390297, 0.909390297, 0.909390297, None, None, None, None, 1.952539482, None, None, 2.728135932, None, 2.728135932, None, 1.952539482, None, 2.728135932, None, None, None, 2.728135932, 2.728135932, None, 2.728135932, None, None, None, 0.766622376, 0.766622376, 0.48813487, None, 0.626092864, 1.952539482, 1, 0.719418115, 0.719418115, 1.234101382, 1.234101382, 0.48813487, 0.48813487, None, None, None, 2.728135932, 2.728135932, 0.909390297, None, 2.728135932, 1, None, 0.629156804, 0.629156804, 0.629156804, 0.629156804, 1.952539482, 0.766622376, 0.766622376, 0.766622376, None, 0.909390297, 0.909390297, 1, 1.573757041, 2.728135932, 2.728135932, 1.952539482, 1.952539482, 0.719418115, 1, 0.909390297, 0.909390297, 0.909390297, None, 2.728135932, None, None, None, None, None, 2.728135932, 2.728135932, 0.909390297, 0.909390297, 1.234101382, 1, 1, 1, 1, 1, 1, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.719418115, 0.719418115, 0.719418115, 2.728135932, None, 0.629156804, 0.909390297, 0.766622376, 1.573757041, 1, None, None, 0.909390297, 0.909390297, 0.909390297, 0.909390297, 0.909390297, 0.909390297, 2.728135932, None, 2.728135932, None, 2.728135932, 2.728135932, 2.728135932, 2.728135932, 2.728135932, None, None, 1, 0.909390297, 0.909390297, 0.629156804, 1.234101382, 2.728135932, 0.909390297, 1, 1, None, 1.952539482, 1.952539482, 1.952539482, 1.952539482, 1.952539482, 1.952539482, 1.952539482, None, 0.629156804, 1, 1, None, None, None, 2.728135932, 2.728135932, 2.728135932, 2.728135932, 2.728135932, 2.728135932, 2.728135932, 2.728135932, 2.728135932, 2.728135932, 2.728135932, 0.719418115, 0.48813487, None, None, 0.629156804, 0.629156804, 0.719418115, 1, None, None, 0.629156804, 0.629156804, 0.719418115, None, None, None, None, 2.728135932, 0.909390297, 0.909390297, 0.909390297, 0.909390297, 0.909390297, 0.909390297, 0.909390297, 0.909390297, None, 1.234101382, 2.728135932, 1.952539482, 2.728135932, None, 1.952539482, 1, 1, 1, 1, 1, None, None, 0.719418115, None, None, None, 2.728135932, 2.728135932, 1.952539482, 0.719418115, 0.909390297, 2.728135932, 2.728135932, 2.728135932, 2.728135932, 0.629156804, 0.629156804, 0.629156804, 0.629156804, 0.629156804, 0.629156804, 0.626092864, None, 2.728135932, 0.766622376, None, 2.728135932, 0.909390297, 1, 2.728135932, 0.629156804, 0.629156804, None, 1.234101382, 0.909390297, 0.909390297, 1.952539482, 1.952539482, 0.626092864, 0.626092864, 1.952539482, 0.719418115, 0.719418115, 0.719418115, 1.952539482, 0.513951956, 0.766622376, 2.728135932, 0.629156804, 0.766622376, 1.234101382, 0.48813487, 0.48813487, 2.728135932, 2.728135932, 0.719418115, 1, 1, 1, 1.573757041, None, None, None, None, None, None, 2.728135932, None, 2.728135932, 2.728135932, 0.719418115, 2.728135932, 0.909390297, 0.909390297, 2.728135932, 2.728135932, None, None, 0.719418115, None, None, None, None, None, None, None, None, 0.766622376, None, None, 0.719418115, 2.728135932, 2.728135932, 0.766622376, None, 1, 2.728135932, None, 0.909390297, 0.629156804, 2.728135932, 2.728135932, 0.909390297, 2.728135932, 2.728135932, 0.909390297, None, 1.234101382, 1.234101382, 0.626092864, 1, 1, 0.766622376, None, 1, 1.234101382, 2.728135932, 2.728135932, 2.728135932, 2.728135932, 2.728135932, 0.629156804, 0.629156804, 1, 1, 1, 1, 1.952539482, None, 0.629156804, 0.909390297, 0.909390297, 2.728135932, 2.728135932, None, None, None, 1.952539482, 1.952539482, 1.952539482, 0.626092864, 2.728135932, 0.766622376, 0.629156804, None, 1, None, 0.719418115, 0.513951956, 1.952539482, 1.952539482, 1, 0.766622376, 0.719418115, None]\n",
    "# excel_file_path = \"production - Copy.xlsx\"\n",
    "# sheet_name = \"Daily Production\"\n",
    "\n",
    "# # Load the Excel file into a DataFrame\n",
    "# daily_production_df = pd.read_excel(excel_file_path, sheet_name=sheet_name)\n",
    "\n",
    "# # Find rows where \"Conversion factor\" is empty\n",
    "# empty_conversion_factor_rows = daily_production_df[daily_production_df[\"Conversion factor\"].isnull()]\n",
    "\n",
    "# # Assign provided data to the empty \"Conversion factor\" rows\n",
    "# empty_conversion_factor_rows[\"Conversion factor\"] = provided_data[:len(empty_conversion_factor_rows)]\n",
    "\n",
    "# # Write the updated DataFrame back to the Excel file\n",
    "# with pd.ExcelWriter(excel_file_path, mode='a', engine=\"openpyxl\") as writer:\n",
    "#     empty_conversion_factor_rows.to_excel(writer, sheet_name=sheet_name, startrow=empty_conversion_factor_rows.index[0], index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c51de67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Provided data\n",
    "# provided_data = [0.344523414, 0.615157241, 0.615157241, 2.728135932, 0.513951956, 0.766622376, None, 0.629156804, 0.909390297, 2.728135932, 0.48813487, 0.766622376, 1.952539482, 1, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.48813487, 0.719418115, None, 2.728135932, None, None, 0.909390297, 2.728135932, 0.766622376, 0.626092864, 0.626092864, None, 2.728135932, 0.909390297, 0.626092864, 0.626092864, 0.719418115, 1.573757041, 0.626092864, 1, 0.909390297, 0.719418115, 2.728135932, None, None, 0.909390297, 3.528414458, 1, 1.952539482, 0.626092864, None, None, 2.728135932, 2.728135932, None, None, None, None, None, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, None, 0.629156804, 0.719418115, None, 0.766622376, 0.626092864, 0.626092864, 0.719418115, 1.573757041, 1.573757041, None, None, 2.728135932, 1, 0.909390297, 0.909390297, 2.728135932, 1.952539482, 0.766622376, 0.766622376, 0.766622376, None, None, 0.626092864, 0.626092864, 0.626092864, 0.626092864, None, 2.728135932, 0.719418115, None, None, None, 0.909390297, None, 0.909390297, 0.626092864, 0.48813487, 0.48813487, 1.234101382, 1, None, None, None, None, None, None, None, None, 2.728135932, 1.234101382, 1.234101382, 1.234101382, 0.719418115, None, 0.766622376, 2.728135932, 0.626092864, 1.952539482, 2.728135932, 0.626092864, 0.626092864, 0.909390297, 0.909390297, 0.909390297, None, None, None, None, 0.48813487, 0.766622376, None, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 2.728135932, 0.719418115, 0.719418115, 0.766622376, 1.952539482, 1.952539482, 1.952539482, 1.952539482, None, 1.952539482, None, 1.952539482, None, 0.626092864, None, 0.909390297, 0.629156804, 0.629156804, 0.629156804, 1, 1, 0.719418115, 0.719418115, 0.766622376, 0.766622376, 2.728135932, 2.728135932, 2.728135932, 2.728135932, 1.234101382, 1.234101382, 1.234101382, 1.234101382, 2.728135932, 0.766622376, None, None, 1, 1, 1, 1, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.626092864, 0.719418115, 2.728135932, 1.952539482, 1.952539482, 0.766622376, 0.766622376, 0.766622376, 0.909390297, None, 0.629156804, 0.629156804, 2.728135932, 0.719418115, 1.573757041, 1.573757041, 1, 1, None, None, None, None, 2.728135932, 1.234101382, 0.48813487, 2.728135932, 2.728135932, 0.626092864, 0.626092864, 0.626092864, None, 1.952539482, 1.952539482, None, 1.952539482, 0.629156804, 2.728135932, None, 1.234101382, 1, 0.909390297, 0.909390297, 0.909390297, 2.728135932, None, None, 1.952539482, 2.728135932, None, None, None, None, 1.234101382, 1.234101382, 1.234101382, 1.234101382, 2.728135932, 2.728135932, 2.728135932, 2.728135932, 2.728135932, 0.719418115, 0.719418115, 0.909390297, 2.728135932, 1, None, 1.952539482, 0.766622376, 0.766622376, 0.629156804, 2.728135932, 1, 1, None, None, 0.719418115, 0.626092864, 0.909390297, 0.719418115, 0.719418115, 0.719418115, 1, 1, 0.629156804, 0.909390297, 2.728135932, 2.728135932, 0.909390297, 0.909390297, 0.909390297, 0.909390297, 0.909390297, 1.952539482, 1.952539482, None, 0.909390297, 2.728135932, 1.573757041, 1.573757041, 1.234101382, 2.728135932, 0.629156804, 0.766622376, 0.766622376, 0.909390297, 0.766622376, 2.728135932, None, 0.909390297, 0.909390297, 0.909390297, 0.909390297, None, None, None, None, 1.952539482, None, None, 2.728135932, None, 2.728135932, None, 1.952539482, None, 2.728135932, None, None, None, 2.728135932, 2.728135932, None, 2.728135932, None, None, None, 0.766622376, 0.766622376, 0.48813487, None, 0.626092864, 1.952539482, 1, 0.719418115, 0.719418115, 1.234101382, 1.234101382, 0.48813487, 0.48813487, None, None, None, 2.728135932, 2.728135932, 0.909390297, None, 2.728135932, 1, None, 0.629156804, 0.629156804, 0.629156804, 0.629156804, 1.952539482, 0.766622376, 0.766622376, 0.766622376, None, 0.909390297, 0.909390297, 1, 1.573757041, 2.728135932, 2.728135932, 1.952539482, 1.952539482, 0.719418115, 1, 0.909390297, 0.909390297, 0.909390297, None, 2.728135932, None, None, None, None, None, 2.728135932, 2.728135932, 0.909390297, 0.909390297, 1.234101382, 1, 1, 1, 1, 1, 1, None, None, 0.719418115, None, None, None, 2.728135932, 2.728135932, 1.952539482, 0.719418115, 0.909390297, 2.728135932, 2.728135932, 2.728135932, 2.728135932, 0.629156804, 0.629156804, 0.629156804, 0.629156804, 0.629156804, 0.629156804, 0.626092864, None, 2.728135932, 0.766622376, None, 2.728135932, 0.909390297, 1, 2.728135932, 0.629156804, 0.629156804, None, 1.234101382, 0.909390297, 0.909390297, 1.952539482, 1.952539482, 0.626092864, 0.626092864, 1.952539482, 0.719418115, 0.719418115, 0.719418115, 1.952539482, 0.513951956, 0.766622376, 2.728135932, 0.629156804, 0.766622376, 1.234101382, 0.48813487, 0.48813487, 2.728135932, 2.728135932, 0.719418115, 1, 1, 1, 1.573757041, None, None, None, None, None, None, 2.728135932, None, 2.728135932, 2.728135932, 0.719418115, 2.728135932, 0.909390297, 0.909390297, 2.728135932, 2.728135932, None, None, 0.719418115, None, None, None, None, None, None, None, None, None, 0.766622376, None, None, 0.719418115, 2.728135932, 2.728135932, 0.766622376, None, 1, 2.728135932, None, 0.909390297, 0.629156804, 2.728135932, 2.728135932, 0.909390297, 2.728135932, 2.728135932, 0.909390297, None, 1.234101382, 1.234101382, 0.626092864, 1, 1, 0.766622376, None, 1, 1.234101382, 2.728135932, 2.728135932, 2.728135932, 2.728135932, 2.728135932, 0.629156804, 0.629156804, 1, 1, 1, 1, 1.952539482, None, 0.629156804, 0.909390297, 0.909390297, 2.728135932, 2.728135932, None, None, None, 1.952539482, 1.952539482, 1.952539482, 0.626092864, 2.728135932, 0.766622376, 0.629156804, None, 1, None, 0.719418115, 0.513951956, 1.952539482, 1.952539482, 1, 0.766622376, 0.719418115, None]\n",
    "\n",
    "# # Load the Excel file\n",
    "# excel_file_path = \"production - Copy.xlsx\"\n",
    "# daily_production_df = pd.read_excel(excel_file_path)\n",
    "\n",
    "# # Find empty \"Conversion factor\" rows\n",
    "# empty_conversion_factor_rows = daily_production_df[daily_production_df[\"Conversion factor\"].isnull()]\n",
    "\n",
    "# # Iterate over the empty rows and update with provided data\n",
    "# for i, row in empty_conversion_factor_rows.iterrows():\n",
    "#     if len(provided_data) > i:\n",
    "#         daily_production_df.at[i, \"Conversion factor\"] = provided_data[i]\n",
    "\n",
    "# # Write the updated DataFrame back to the Excel file\n",
    "# with pd.ExcelWriter(excel_file_path, mode='a', engine=\"openpyxl\") as writer:\n",
    "#     daily_production_df.to_excel(writer, sheet_name=\"Daily Production\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da06af2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load the Excel file\n",
    "# excel_file_path = \"production - Copy.xlsx\"\n",
    "# daily_production_df = pd.read_excel(excel_file_path, sheet_name=\"Daily Production\")\n",
    "\n",
    "# # Find empty \"Conversion factor\" cells\n",
    "# empty_conversion_factor_cells = daily_production_df[daily_production_df[\"Conversion factor\"].isnull()].index\n",
    "\n",
    "# # Iterate over the empty cells and update with provided data\n",
    "# for i, cell_index in enumerate(empty_conversion_factor_cells):\n",
    "#     if len(provided_data) > i:\n",
    "#         daily_production_df.at[cell_index, \"Conversion factor\"] = provided_data[i]\n",
    "\n",
    "# # Write the updated DataFrame back to the Excel file\n",
    "# with pd.ExcelWriter(excel_file_path, mode='a', engine=\"openpyxl\") as writer:\n",
    "#     daily_production_df.to_excel(writer, sheet_name=\"Daily Production\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a1fc560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60acbad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "PATH=\"C:\\\\Users\\\\jashfaque\\\\Desktop\\\\dashboardSoft\\\\chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfc5ddc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e9a71d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a39909cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "47294c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"http://192.168.168.216/premierJute/myPanel/userdefinedreports\")\n",
    "\n",
    "wait = WebDriverWait(driver, 60)\n",
    "\n",
    "# Find and select the input field with ID \"txtfromdate\"\n",
    "input_field = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='txtfromdate']\")))\n",
    "input_field.click()\n",
    "\n",
    "\n",
    "# Find and click the button with ID \"btnFrmS1\"\n",
    "button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='btnFrmS1']\")))\n",
    "driver.execute_script(\"arguments[0].click();\", button)\n",
    "\n",
    "\n",
    "# Find and click the input field with ID \"txttodate\"\n",
    "input_field = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='txttodate']\")))\n",
    "input_field.click()\n",
    "\n",
    "# Find and click the button with ID \"btnToS3\"\n",
    "button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='btnToS1']\")))\n",
    "button.click()\n",
    "\n",
    "# Wait for a brief period before clicking the next button\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Click on the dropdown\n",
    "dropdown = wait.until(EC.element_to_be_clickable((By.ID, \"select2-body_ddlreportemp-container\")))\n",
    "dropdown.click()\n",
    "\n",
    "\n",
    "# Locate and click the \"Breakage\" option\n",
    "manager_option = wait.until(EC.element_to_be_clickable((By.XPATH, \"//li[contains(text(), 'Breakage')]\")))\n",
    "manager_option.click()\n",
    "\n",
    "# Find the \"Load\" button element\n",
    "load_button_1 = wait.until(EC.element_to_be_clickable((By.ID, \"Btnsearchid\")))\n",
    "\n",
    "# Click the \"Load\" button\n",
    "load_button_1.click()\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "html_code_br = driver.page_source\n",
    "# Parse the HTML content\n",
    "\n",
    "soup_br = BeautifulSoup(html_code_br, 'html.parser')\n",
    "\n",
    "# Find the table element\n",
    "table_br = soup_br.find('table', {'id': 'usertable'})  # Replace 'tblline' with the actual ID of your table\n",
    "\n",
    "# Extract the table headers\n",
    "headers_br = [th.text.strip() for th in table_br.select('thead th')]\n",
    "\n",
    "# Extract the table rows\n",
    "rows_br = []\n",
    "for tr in table_br.select('tbody tr'):\n",
    "    row_br = [td.text.strip() for td in tr.select('td')]\n",
    "    rows_br.append(row_br)\n",
    "\n",
    "# Check if there are any rows in the footer of the table\n",
    "footer_rows_br = table_br.select('tfoot tr')\n",
    "if footer_rows_br:\n",
    "    # Extract the additional rows from the footer\n",
    "    additional_rows_br = []\n",
    "    for tr in footer_rows_br:\n",
    "        row_br = [td.text.strip() for td in tr.select('td')]\n",
    "        additional_rows_br.append(row_br)\n",
    "\n",
    "    # Add the additional rows at the end of the extracted rows\n",
    "    rows_br.extend(additional_rows_br)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df_br = pd.DataFrame(rows_br, columns=headers_br)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df_br.to_excel('breakage_A.xlsx', index=False)\n",
    "\n",
    "\n",
    "\n",
    "time.sleep(10)\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2110b29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"http://192.168.168.216/premierJute/myPanel/userdefinedreports\")\n",
    "\n",
    "wait = WebDriverWait(driver, 60)\n",
    "\n",
    "# Find and select the input field with ID \"txtfromdate\"\n",
    "input_field = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='txtfromdate']\")))\n",
    "input_field.click()\n",
    "\n",
    "\n",
    "# Find and click the button with ID \"btnFrmS1\"\n",
    "button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='btnFrmS2']\")))\n",
    "driver.execute_script(\"arguments[0].click();\", button)\n",
    "\n",
    "\n",
    "# Find and click the input field with ID \"txttodate\"\n",
    "input_field = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='txttodate']\")))\n",
    "input_field.click()\n",
    "\n",
    "# Find and click the button with ID \"btnToS3\"\n",
    "button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='btnToS2']\")))\n",
    "button.click()\n",
    "\n",
    "# Wait for a brief period before clicking the next button\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Click on the dropdown\n",
    "dropdown = wait.until(EC.element_to_be_clickable((By.ID, \"select2-body_ddlreportemp-container\")))\n",
    "dropdown.click()\n",
    "\n",
    "\n",
    "# Locate and click the \"Breakage\" option\n",
    "manager_option = wait.until(EC.element_to_be_clickable((By.XPATH, \"//li[contains(text(), 'Breakage')]\")))\n",
    "manager_option.click()\n",
    "\n",
    "# Find the \"Load\" button element\n",
    "load_button_1 = wait.until(EC.element_to_be_clickable((By.ID, \"Btnsearchid\")))\n",
    "\n",
    "# Click the \"Load\" button\n",
    "load_button_1.click()\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "html_code_br = driver.page_source\n",
    "# Parse the HTML content\n",
    "\n",
    "soup_br = BeautifulSoup(html_code_br, 'html.parser')\n",
    "\n",
    "# Find the table element\n",
    "table_br = soup_br.find('table', {'id': 'usertable'})  # Replace 'tblline' with the actual ID of your table\n",
    "\n",
    "# Extract the table headers\n",
    "headers_br = [th.text.strip() for th in table_br.select('thead th')]\n",
    "\n",
    "# Extract the table rows\n",
    "rows_br = []\n",
    "for tr in table_br.select('tbody tr'):\n",
    "    row_br = [td.text.strip() for td in tr.select('td')]\n",
    "    rows_br.append(row_br)\n",
    "\n",
    "# Check if there are any rows in the footer of the table\n",
    "footer_rows_br = table_br.select('tfoot tr')\n",
    "if footer_rows_br:\n",
    "    # Extract the additional rows from the footer\n",
    "    additional_rows_br = []\n",
    "    for tr in footer_rows_br:\n",
    "        row_br = [td.text.strip() for td in tr.select('td')]\n",
    "        additional_rows_br.append(row_br)\n",
    "\n",
    "    # Add the additional rows at the end of the extracted rows\n",
    "    rows_br.extend(additional_rows_br)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df_br = pd.DataFrame(rows_br, columns=headers_br)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df_br.to_excel('breakage_B.xlsx', index=False)\n",
    "\n",
    "\n",
    "\n",
    "time.sleep(10)\n",
    "driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0499b149",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"http://192.168.168.216/premierJute/myPanel/userdefinedreports\")\n",
    "\n",
    "wait = WebDriverWait(driver, 60)\n",
    "\n",
    "# Find and select the input field with ID \"txtfromdate\"\n",
    "input_field = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='txtfromdate']\")))\n",
    "input_field.click()\n",
    "\n",
    "\n",
    "# Find and click the button with ID \"btnFrmS1\"\n",
    "button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='btnFrmS3']\")))\n",
    "driver.execute_script(\"arguments[0].click();\", button)\n",
    "\n",
    "\n",
    "# Find and click the input field with ID \"txttodate\"\n",
    "input_field = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='txttodate']\")))\n",
    "input_field.click()\n",
    "\n",
    "# Find and click the button with ID \"btnToS3\"\n",
    "button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='btnToS3']\")))\n",
    "button.click()\n",
    "\n",
    "# Wait for a brief period before clicking the next button\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Click on the dropdown\n",
    "dropdown = wait.until(EC.element_to_be_clickable((By.ID, \"select2-body_ddlreportemp-container\")))\n",
    "dropdown.click()\n",
    "\n",
    "\n",
    "# Locate and click the \"Breakage\" option\n",
    "manager_option = wait.until(EC.element_to_be_clickable((By.XPATH, \"//li[contains(text(), 'Breakage')]\")))\n",
    "manager_option.click()\n",
    "\n",
    "# Find the \"Load\" button element\n",
    "load_button_1 = wait.until(EC.element_to_be_clickable((By.ID, \"Btnsearchid\")))\n",
    "\n",
    "# Click the \"Load\" button\n",
    "load_button_1.click()\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "html_code_br = driver.page_source\n",
    "# Parse the HTML content\n",
    "\n",
    "soup_br = BeautifulSoup(html_code_br, 'html.parser')\n",
    "\n",
    "# Find the table element\n",
    "table_br = soup_br.find('table', {'id': 'usertable'})  # Replace 'tblline' with the actual ID of your table\n",
    "\n",
    "# Extract the table headers\n",
    "headers_br = [th.text.strip() for th in table_br.select('thead th')]\n",
    "\n",
    "# Extract the table rows\n",
    "rows_br = []\n",
    "for tr in table_br.select('tbody tr'):\n",
    "    row_br = [td.text.strip() for td in tr.select('td')]\n",
    "    rows_br.append(row_br)\n",
    "\n",
    "# Check if there are any rows in the footer of the table\n",
    "footer_rows_br = table_br.select('tfoot tr')\n",
    "if footer_rows_br:\n",
    "    # Extract the additional rows from the footer\n",
    "    additional_rows_br = []\n",
    "    for tr in footer_rows_br:\n",
    "        row_br = [td.text.strip() for td in tr.select('td')]\n",
    "        additional_rows_br.append(row_br)\n",
    "\n",
    "    # Add the additional rows at the end of the extracted rows\n",
    "    rows_br.extend(additional_rows_br)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df_br = pd.DataFrame(rows_br, columns=headers_br)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df_br.to_excel('breakage_C.xlsx', index=False)\n",
    "\n",
    "\n",
    "\n",
    "time.sleep(10)\n",
    "driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cb3df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f6e23c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"http://192.168.168.216/premierJute/myPanel/trendcomparison\")\n",
    "\n",
    "wait = WebDriverWait(driver, 60)\n",
    "\n",
    "\n",
    "# Find the button using the provided relative XPath\n",
    "button = wait.until(EC.visibility_of_element_located((By.XPATH, \"//label[@id='lnum']\")))\n",
    "\n",
    "driver.set_window_size(1200, 800)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# Click on the button\n",
    "button.click()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "html_code = driver.page_source\n",
    "# Create a BeautifulSoup object\n",
    "soup = BeautifulSoup(html_code, 'html.parser')\n",
    "\n",
    "# Find the table element\n",
    "table = soup.find('table', {'id': 'tblline'})\n",
    "\n",
    "# Extract the table headers\n",
    "headers = [th.text for th in table.find('thead').find_all('th')]\n",
    "\n",
    "# Extract the table rows\n",
    "rows = []\n",
    "for tr in table.find('tbody').find_all('tr'):\n",
    "    row = [td.text.strip() for td in tr.find_all('td')]\n",
    "    if row:\n",
    "        rows.append(row)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df.to_excel('kg.xlsx', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Execute JavaScript to unselect the checkbox\n",
    "driver.execute_script(\"document.querySelector(\\\"label[for='chk40']\\\").previousElementSibling.checked = false;\")\n",
    "\n",
    "\n",
    "# Execute JavaScript to select the first checkbox\n",
    "driver.execute_script(\"document.querySelector(\\\"label[for='chk9']\\\").click();\")\n",
    "\n",
    "# Wait for a brief moment\n",
    "time.sleep(2)\n",
    "\n",
    "# Execute JavaScript to select the second checkbox\n",
    "driver.execute_script(\"document.querySelector(\\\"label[for='chk69']\\\").click();\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extract the HTML content of the page\n",
    "html_code_2 = driver.page_source\n",
    "\n",
    "# Parse the HTML code with BeautifulSoup\n",
    "soup_2 = BeautifulSoup(html_code_2, 'html.parser')\n",
    "\n",
    "# Find the table element\n",
    "table_2 = soup_2.find('table', {'id': 'tblline'})\n",
    "\n",
    "# Extract the table headers\n",
    "headers_2 = [th.text.strip() for th in table_2.select('thead th')]\n",
    "\n",
    "# Extract the table rows\n",
    "rows_2 = []\n",
    "for tr in table_2.select('tbody tr'):\n",
    "    row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "    rows_2.append(row_2)\n",
    "\n",
    "# Check if there are any rows in the footer of the table\n",
    "footer_rows_2 = table_2.select('tfoot tr')\n",
    "if footer_rows_2:\n",
    "    # Extract the additional rows from the footer\n",
    "    additional_rows_2 = []\n",
    "    for tr in footer_rows_2:\n",
    "        row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "        additional_rows_2.append(row_2)\n",
    "\n",
    "    # Add the additional rows at the end of the extracted rows\n",
    "    rows_2.extend(additional_rows_2)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df_2 = pd.DataFrame(rows_2, columns=headers_2)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df_2.to_excel('trendline_1.xlsx', index=False)\n",
    "\n",
    "\n",
    "# Execute JavaScript to unselect the first checkbox\n",
    "driver.execute_script(\"document.querySelector(\\\"label[for='chk9']\\\").click();\")\n",
    "\n",
    "# Wait for a brief moment\n",
    "time.sleep(2)\n",
    "\n",
    "# Execute JavaScript to unselect the second checkbox\n",
    "driver.execute_script(\"document.querySelector(\\\"label[for='chk69']\\\").click();\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Execute JavaScript to select the first checkbox\n",
    "driver.execute_script(\"document.querySelector(\\\"label[for='chk15']\\\").click();\")\n",
    "\n",
    "# Wait for a brief moment\n",
    "time.sleep(2)\n",
    "\n",
    "# Execute JavaScript to select the second checkbox\n",
    "driver.execute_script(\"document.querySelector(\\\"label[for='chk32']\\\").click();\")\n",
    "\n",
    "\n",
    "# Extract the HTML content of the page\n",
    "html_code_2 = driver.page_source\n",
    "\n",
    "# Parse the HTML code with BeautifulSoup\n",
    "soup_2 = BeautifulSoup(html_code_2, 'html.parser')\n",
    "\n",
    "# Find the table element\n",
    "table_2 = soup_2.find('table', {'id': 'tblline'})\n",
    "\n",
    "# Extract the table headers\n",
    "headers_2 = [th.text.strip() for th in table_2.select('thead th')]\n",
    "\n",
    "# Extract the table rows\n",
    "rows_2 = []\n",
    "for tr in table_2.select('tbody tr'):\n",
    "    row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "    rows_2.append(row_2)\n",
    "\n",
    "# Check if there are any rows in the footer of the table\n",
    "footer_rows_2 = table_2.select('tfoot tr')\n",
    "if footer_rows_2:\n",
    "    # Extract the additional rows from the footer\n",
    "    additional_rows_2 = []\n",
    "    for tr in footer_rows_2:\n",
    "        row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "        additional_rows_2.append(row_2)\n",
    "\n",
    "    # Add the additional rows at the end of the extracted rows\n",
    "    rows_2.extend(additional_rows_2)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df_2 = pd.DataFrame(rows_2, columns=headers_2)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df_2.to_excel('trendline_2.xlsx', index=False)\n",
    "\n",
    "\n",
    "# Function to convert columns to numeric except for specified columns\n",
    "def convert_columns_to_numeric(df, exclude_columns):\n",
    "    converted_df = df.copy()\n",
    "    for column in df.columns:\n",
    "        if column not in exclude_columns:\n",
    "            converted_df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "    return converted_df\n",
    "\n",
    "# List of Excel file names\n",
    "excel_files = [\"trendline_1.xlsx\",\"trendline_2.xlsx\"]\n",
    "\n",
    "\n",
    "\n",
    "# List of columns to exclude from conversion\n",
    "exclude_columns = [\"Period\"]\n",
    "\n",
    "# Process each Excel file\n",
    "for file in excel_files:\n",
    "    # Read Excel file\n",
    "    df = pd.read_excel(file)\n",
    "    \n",
    "    # Convert columns to numeric\n",
    "    converted_df = convert_columns_to_numeric(df, exclude_columns)\n",
    "    \n",
    "    # Save the modified DataFrame back to the same Excel file\n",
    "    converted_df.to_excel(file, index=False)\n",
    "\n",
    "\n",
    "time.sleep(10)\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d9942bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manager\n",
    "\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to the webpage\n",
    "driver.get(\"http://192.168.168.216/premierJute/myPanel/userdefinedreports\")\n",
    "\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "# Find and click the 'From Date' input field to open the calendar\n",
    "from_date_input = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='txtfromdate']\")))\n",
    "from_date_input.click()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Find and click the 'From S1' button\n",
    "from_s1_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='btnFrmS1']\")))\n",
    "from_s1_button.click()\n",
    "\n",
    "# Find and click the 'To Date' input field to open the calendar\n",
    "to_date_input = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='txttodate']\")))\n",
    "to_date_input.click()\n",
    "\n",
    "\n",
    "to_s3_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='btnToS1']\")))\n",
    "driver.execute_script(\"arguments[0].scrollIntoView();\", to_s3_button)\n",
    "driver.execute_script(\"arguments[0].click();\", to_s3_button)\n",
    "\n",
    "# Click on the dropdown\n",
    "dropdown = wait.until(EC.element_to_be_clickable((By.ID, \"select2-body_ddlreportemp-container\")))\n",
    "dropdown.click()\n",
    "\n",
    "\n",
    "# Locate and click the \"Manager\" option\n",
    "manager_option = wait.until(EC.element_to_be_clickable((By.XPATH, \"//li[contains(text(), 'Manager')]\")))\n",
    "manager_option.click()\n",
    "\n",
    "# Click on the \"Load\" button\n",
    "load_button = wait.until(EC.element_to_be_clickable((By.ID, \"Btnsearchid\")))\n",
    "load_button.click()\n",
    "time.sleep(5)\n",
    "\n",
    "# Click on the desired button\n",
    "# Find and click the dropdown button\n",
    "# dropdown_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@data-toggle='dropdown']\")))\n",
    "# dropdown_button.click()\n",
    "\n",
    "# # Click the third button\n",
    "# third_button.click()\n",
    "\n",
    "# # Find the dropdown menu\n",
    "# dropdown_menu = wait.until(EC.presence_of_element_located((By.ID, \"drpsorting\")))\n",
    "\n",
    "# # Find and click the button with the text \"Excel\"\n",
    "# excel_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//a[normalize-space()='Excel']\")))\n",
    "\n",
    "# excel_button.click()\n",
    "\n",
    "# Extract the HTML content of the page\n",
    "\n",
    "html_code_2 = driver.page_source\n",
    "# Parse the HTML content\n",
    "\n",
    "soup_2 = BeautifulSoup(html_code_2, 'html.parser')\n",
    "\n",
    "# Find the table element\n",
    "table_2 = soup_2.find('table', {'id': 'usertable'})  # Replace 'tblline' with the actual ID of your table\n",
    "\n",
    "# Extract the table headers\n",
    "headers_2 = [th.text.strip() for th in table_2.select('thead th')]\n",
    "\n",
    "# Extract the table rows\n",
    "rows_2 = []\n",
    "for tr in table_2.select('tbody tr'):\n",
    "    row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "    rows_2.append(row_2)\n",
    "\n",
    "# Check if there are any rows in the footer of the table\n",
    "footer_rows_2 = table_2.select('tfoot tr')\n",
    "if footer_rows_2:\n",
    "    # Extract the additional rows from the footer\n",
    "    additional_rows_2 = []\n",
    "    for tr in footer_rows_2:\n",
    "        row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "        additional_rows_2.append(row_2)\n",
    "\n",
    "    # Add the additional rows at the end of the extracted rows\n",
    "    rows_2.extend(additional_rows_2)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df_2 = pd.DataFrame(rows_2, columns=headers_2)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df_2.to_excel('manager_A.xlsx', index=False)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a993774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manager\n",
    "\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to the webpage\n",
    "driver.get(\"http://192.168.168.216/premierJute/myPanel/userdefinedreports\")\n",
    "\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "# Find and click the 'From Date' input field to open the calendar\n",
    "from_date_input = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='txtfromdate']\")))\n",
    "from_date_input.click()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Find and click the 'From S1' button\n",
    "from_s1_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='btnFrmS2']\")))\n",
    "from_s1_button.click()\n",
    "\n",
    "# Find and click the 'To Date' input field to open the calendar\n",
    "to_date_input = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='txttodate']\")))\n",
    "to_date_input.click()\n",
    "\n",
    "\n",
    "to_s3_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='btnToS2']\")))\n",
    "driver.execute_script(\"arguments[0].scrollIntoView();\", to_s3_button)\n",
    "driver.execute_script(\"arguments[0].click();\", to_s3_button)\n",
    "\n",
    "# Click on the dropdown\n",
    "dropdown = wait.until(EC.element_to_be_clickable((By.ID, \"select2-body_ddlreportemp-container\")))\n",
    "dropdown.click()\n",
    "\n",
    "\n",
    "# Locate and click the \"Manager\" option\n",
    "manager_option = wait.until(EC.element_to_be_clickable((By.XPATH, \"//li[contains(text(), 'Manager')]\")))\n",
    "manager_option.click()\n",
    "\n",
    "# Click on the \"Load\" button\n",
    "load_button = wait.until(EC.element_to_be_clickable((By.ID, \"Btnsearchid\")))\n",
    "load_button.click()\n",
    "time.sleep(5)\n",
    "\n",
    "# Click on the desired button\n",
    "# Find and click the dropdown button\n",
    "# dropdown_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@data-toggle='dropdown']\")))\n",
    "# dropdown_button.click()\n",
    "\n",
    "# # Click the third button\n",
    "# third_button.click()\n",
    "\n",
    "# # Find the dropdown menu\n",
    "# dropdown_menu = wait.until(EC.presence_of_element_located((By.ID, \"drpsorting\")))\n",
    "\n",
    "# # Find and click the button with the text \"Excel\"\n",
    "# excel_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//a[normalize-space()='Excel']\")))\n",
    "\n",
    "# excel_button.click()\n",
    "\n",
    "# Extract the HTML content of the page\n",
    "\n",
    "html_code_2 = driver.page_source\n",
    "# Parse the HTML content\n",
    "\n",
    "soup_2 = BeautifulSoup(html_code_2, 'html.parser')\n",
    "\n",
    "# Find the table element\n",
    "table_2 = soup_2.find('table', {'id': 'usertable'})  # Replace 'tblline' with the actual ID of your table\n",
    "\n",
    "# Extract the table headers\n",
    "headers_2 = [th.text.strip() for th in table_2.select('thead th')]\n",
    "\n",
    "# Extract the table rows\n",
    "rows_2 = []\n",
    "for tr in table_2.select('tbody tr'):\n",
    "    row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "    rows_2.append(row_2)\n",
    "\n",
    "# Check if there are any rows in the footer of the table\n",
    "footer_rows_2 = table_2.select('tfoot tr')\n",
    "if footer_rows_2:\n",
    "    # Extract the additional rows from the footer\n",
    "    additional_rows_2 = []\n",
    "    for tr in footer_rows_2:\n",
    "        row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "        additional_rows_2.append(row_2)\n",
    "\n",
    "    # Add the additional rows at the end of the extracted rows\n",
    "    rows_2.extend(additional_rows_2)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df_2 = pd.DataFrame(rows_2, columns=headers_2)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df_2.to_excel('manager_B.xlsx', index=False)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2c6d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manager\n",
    "\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to the webpage\n",
    "driver.get(\"http://192.168.168.216/premierJute/myPanel/userdefinedreports\")\n",
    "\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "# Find and click the 'From Date' input field to open the calendar\n",
    "from_date_input = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='txtfromdate']\")))\n",
    "from_date_input.click()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Find and click the 'From S1' button\n",
    "from_s1_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='btnFrmS3']\")))\n",
    "from_s1_button.click()\n",
    "\n",
    "# Find and click the 'To Date' input field to open the calendar\n",
    "to_date_input = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='txttodate']\")))\n",
    "to_date_input.click()\n",
    "\n",
    "\n",
    "to_s3_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='btnToS3']\")))\n",
    "driver.execute_script(\"arguments[0].scrollIntoView();\", to_s3_button)\n",
    "driver.execute_script(\"arguments[0].click();\", to_s3_button)\n",
    "\n",
    "# Click on the dropdown\n",
    "dropdown = wait.until(EC.element_to_be_clickable((By.ID, \"select2-body_ddlreportemp-container\")))\n",
    "dropdown.click()\n",
    "\n",
    "\n",
    "# Locate and click the \"Manager\" option\n",
    "manager_option = wait.until(EC.element_to_be_clickable((By.XPATH, \"//li[contains(text(), 'Manager')]\")))\n",
    "manager_option.click()\n",
    "\n",
    "# Click on the \"Load\" button\n",
    "load_button = wait.until(EC.element_to_be_clickable((By.ID, \"Btnsearchid\")))\n",
    "load_button.click()\n",
    "time.sleep(5)\n",
    "\n",
    "# Click on the desired button\n",
    "# Find and click the dropdown button\n",
    "# dropdown_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@data-toggle='dropdown']\")))\n",
    "# dropdown_button.click()\n",
    "\n",
    "# # Click the third button\n",
    "# third_button.click()\n",
    "\n",
    "# # Find the dropdown menu\n",
    "# dropdown_menu = wait.until(EC.presence_of_element_located((By.ID, \"drpsorting\")))\n",
    "\n",
    "# # Find and click the button with the text \"Excel\"\n",
    "# excel_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//a[normalize-space()='Excel']\")))\n",
    "\n",
    "# excel_button.click()\n",
    "\n",
    "# Extract the HTML content of the page\n",
    "\n",
    "html_code_2 = driver.page_source\n",
    "# Parse the HTML content\n",
    "\n",
    "soup_2 = BeautifulSoup(html_code_2, 'html.parser')\n",
    "\n",
    "# Find the table element\n",
    "table_2 = soup_2.find('table', {'id': 'usertable'})  # Replace 'tblline' with the actual ID of your table\n",
    "\n",
    "# Extract the table headers\n",
    "headers_2 = [th.text.strip() for th in table_2.select('thead th')]\n",
    "\n",
    "# Extract the table rows\n",
    "rows_2 = []\n",
    "for tr in table_2.select('tbody tr'):\n",
    "    row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "    rows_2.append(row_2)\n",
    "\n",
    "# Check if there are any rows in the footer of the table\n",
    "footer_rows_2 = table_2.select('tfoot tr')\n",
    "if footer_rows_2:\n",
    "    # Extract the additional rows from the footer\n",
    "    additional_rows_2 = []\n",
    "    for tr in footer_rows_2:\n",
    "        row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "        additional_rows_2.append(row_2)\n",
    "\n",
    "    # Add the additional rows at the end of the extracted rows\n",
    "    rows_2.extend(additional_rows_2)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df_2 = pd.DataFrame(rows_2, columns=headers_2)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df_2.to_excel('manager_C.xlsx', index=False)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd5ef970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for breakage\n",
    "import pandas as pd\n",
    "\n",
    "# Function to convert columns to numeric except for specified columns\n",
    "def convert_columns_to_numeric(df, exclude_columns):\n",
    "    converted_df = df.copy()\n",
    "    for column in df.columns:\n",
    "        if column not in exclude_columns:\n",
    "            converted_df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "    return converted_df\n",
    "\n",
    "# List of Excel file names\n",
    "excel_files = [\"breakage_A.xlsx\", \"breakage_B.xlsx\", \"breakage_C.xlsx\"]\n",
    "\n",
    "# List of columns to exclude from conversion\n",
    "exclude_columns = [\"Count and Material\"]\n",
    "\n",
    "# Process each Excel file\n",
    "for file in excel_files:\n",
    "    # Read Excel file\n",
    "    df = pd.read_excel(file)\n",
    "    \n",
    "    # Convert columns to numeric\n",
    "    converted_df = convert_columns_to_numeric(df, exclude_columns)\n",
    "    \n",
    "    # Save the modified DataFrame back to the same Excel file\n",
    "    converted_df.to_excel(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e2137e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe474f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for manager\n",
    "import pandas as pd\n",
    "\n",
    "# Function to convert columns to numeric except for specified columns\n",
    "def convert_columns_to_numeric(df, exclude_columns):\n",
    "    converted_df = df.copy()\n",
    "    for column in df.columns:\n",
    "        if column not in exclude_columns:\n",
    "            converted_df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "    return converted_df\n",
    "\n",
    "# List of Excel file names\n",
    "excel_files = [\"manager_A.xlsx\", \"manager_B.xlsx\", \"manager_C.xlsx\"]\n",
    "\n",
    "# List of columns to exclude from conversion\n",
    "exclude_columns = [\"Count and Material\"]\n",
    "\n",
    "# Process each Excel file\n",
    "for file in excel_files:\n",
    "    # Read Excel file\n",
    "    df = pd.read_excel(file)\n",
    "    \n",
    "    # Convert columns to numeric\n",
    "    converted_df = convert_columns_to_numeric(df, exclude_columns)\n",
    "    \n",
    "    # Save the modified DataFrame back to the same Excel file\n",
    "    converted_df.to_excel(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a5812f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Set up the Selenium webdriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to the web page\n",
    "driver.get(\"your_website_url_here\")\n",
    "\n",
    "# Find and input the 'From Date'\n",
    "from_date_input = driver.find_element(By.XPATH, \"//input[@id='txtfromdate']\")\n",
    "from_date_input.click()\n",
    "\n",
    "# Click on the 'From' button\n",
    "from_button = driver.find_element(By.XPATH, \"//button[@id='btnFrmS1']\")\n",
    "from_button.click()\n",
    "\n",
    "# Find and input the 'To Date'\n",
    "to_date_input = driver.find_element(By.XPATH, \"//input[@id='txttodate']\")\n",
    "to_date_input.click()\n",
    "\n",
    "# Click on the 'To' button\n",
    "to_button = driver.find_element(By.XPATH, \"//button[@id='btnToS3']\")\n",
    "to_button.click()\n",
    "\n",
    "# Click on the employee dropdown\n",
    "employee_dropdown = driver.find_element(By.XPATH, \"//span[@id='select2-body_ddlreportemp-container']\")\n",
    "employee_dropdown.click()\n",
    "\n",
    "# Wait until the dropdown options are visible\n",
    "dropdown_options = WebDriverWait(driver, 10).until(\n",
    "    EC.visibility_of_all_elements_located((By.XPATH, \"//span[@class='select2-dropdown select2-dropdown--below']//li\"))\n",
    ")\n",
    "\n",
    "# Choose the desired option from the dropdown\n",
    "desired_option = \"your_desired_option_text_here\"\n",
    "for option in dropdown_options:\n",
    "    if option.text == desired_option:\n",
    "        option.click()\n",
    "        break\n",
    "\n",
    "# Click on the search button\n",
    "search_button = driver.find_element(By.XPATH, \"//button[@id='Btnsearchid']\")\n",
    "search_button.click()\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "002b2a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'AEF %' not found in the file: manager_B.xlsx. Skipping filtering.\n",
      "Column 'AEF %' not found in the file: manager_C.xlsx. Skipping filtering.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of Excel file names\n",
    "excel_files = [\"manager_A.xlsx\", \"manager_B.xlsx\", \"manager_C.xlsx\"]\n",
    "\n",
    "# Process each Excel file\n",
    "for file in excel_files:\n",
    "    # Read Excel file\n",
    "    df = pd.read_excel(file)\n",
    "    \n",
    "    # Check if \"AEF %\" column exists in the DataFrame\n",
    "    if \"AEF %\" in df.columns:\n",
    "        # Filter rows based on condition\n",
    "        df = df[df[\"AEF %\"] > 30]\n",
    "        \n",
    "        # Save the filtered DataFrame back to the same Excel file\n",
    "        df.to_excel(file, index=False)\n",
    "    else:\n",
    "        print(f\"Column 'AEF %' not found in the file: {file}. Skipping filtering.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83474dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "manager_df_A=pd.read_excel(\"manager_A.xlsx\")\n",
    "\n",
    "running_frame=manager_df_A[\"AEF %\"][:-1].count() #C23\n",
    "avg_efficiency=manager_df_A[\"AEF %\"][:-1].mean()\n",
    "avg_efficiency_percentage = \"{:.2f}%\".format(avg_efficiency)#C24\n",
    "total_idle_spndl=manager_df_A[\"eb idle\"][:-1].sum() #C28\n",
    "total_doffing=manager_df_A[\"doffs\"][:-1].sum() #C30\n",
    "avg_min_doff=manager_df_A[\"min/doff\"][:-1].mean() #C31\n",
    "stop_minutes=manager_df_A[\"Total M/c Stop time\"][:-1].sum() #C32\n",
    "total_end_br=manager_df_A[\"eb total\"][:-1].sum() #C33\n",
    "                                     \n",
    "\n",
    "                                     # Load the workbook\n",
    "# Load the workbook\n",
    "workbook = load_workbook(\"UltimoJJ analysis report.xlsx\")\n",
    "\n",
    "# Select the desired sheet (e.g., Summary)\n",
    "sheet = workbook[\"Summary\"]\n",
    "\n",
    "# Write the data to specific cells\n",
    "sheet[\"C23\"] = running_frame\n",
    "sheet[\"C24\"] = avg_efficiency_percentage\n",
    "sheet[\"C28\"] = total_idle_spndl\n",
    "sheet[\"C30\"] = total_doffing\n",
    "sheet[\"C31\"] = avg_min_doff\n",
    "sheet[\"C32\"] = stop_minutes\n",
    "sheet[\"C33\"] = total_end_br\n",
    "\n",
    "\n",
    "manager_df_B=pd.read_excel(\"manager_B.xlsx\")\n",
    "\n",
    "running_frame=manager_df_B[\"AEF %\"][:-1].count() \n",
    "avg_efficiency=manager_df_B[\"AEF %\"][:-1].mean()\n",
    "avg_efficiency_percentage = \"{:.2f}%\".format(avg_efficiency)\n",
    "total_idle_spndl=manager_df_B[\"eb idle\"][:-1].sum() \n",
    "total_doffing=manager_df_B[\"doffs\"][:-1].sum() \n",
    "avg_min_doff=manager_df_B[\"min/doff\"][:-1].mean() \n",
    "stop_minutes=manager_df_B[\"Total M/c Stop time\"][:-1].sum()\n",
    "total_end_br=manager_df_B[\"eb total\"][:-1].sum() \n",
    "\n",
    "\n",
    "# Write the data to specific cells\n",
    "sheet[\"F23\"] = running_frame\n",
    "sheet[\"F24\"] = avg_efficiency_percentage\n",
    "sheet[\"F28\"] = total_idle_spndl\n",
    "sheet[\"F30\"] = total_doffing\n",
    "sheet[\"F31\"] = avg_min_doff\n",
    "sheet[\"F32\"] = stop_minutes\n",
    "sheet[\"F33\"] = total_end_br\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "manager_df_C=pd.read_excel(\"manager_C.xlsx\")\n",
    "\n",
    "running_frame=manager_df_C[\"AEF %\"][:-1].count() \n",
    "avg_efficiency=manager_df_C[\"AEF %\"][:-1].mean()\n",
    "avg_efficiency_percentage = \"{:.2f}%\".format(avg_efficiency)\n",
    "total_idle_spndl=manager_df_C[\"eb idle\"][:-1].sum() \n",
    "total_doffing=manager_df_C[\"doffs\"][:-1].sum() \n",
    "avg_min_doff=manager_df_C[\"min/doff\"][:-1].mean() \n",
    "stop_minutes=manager_df_C[\"Total M/c Stop time\"][:-1].sum() \n",
    "total_end_br=manager_df_C[\"eb total\"][:-1].sum() \n",
    "\n",
    "\n",
    "# Write the data to specific cells\n",
    "sheet[\"I23\"] = running_frame\n",
    "sheet[\"I24\"] = avg_efficiency_percentage\n",
    "sheet[\"I28\"] = total_idle_spndl\n",
    "sheet[\"I30\"] = total_doffing\n",
    "sheet[\"I31\"] = avg_min_doff\n",
    "sheet[\"I32\"] = stop_minutes\n",
    "sheet[\"I33\"] = total_end_br\n",
    "\n",
    "# Save the modified workbook\n",
    "workbook.save(\"UltimoJJ analysis report.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32cde277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.43214285714286\n"
     ]
    }
   ],
   "source": [
    "print(manager_df_A[\"AEF %\"][:-1].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
