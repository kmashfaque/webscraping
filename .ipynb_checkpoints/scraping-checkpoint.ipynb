{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b1e8c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'AEF %' not found in the file: manager_C.xlsx. Skipping filtering.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jashfaque\\AppData\\Local\\Temp\\ipykernel_18696\\1150252654.py:930: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_data = combined_data.append(df, ignore_index=True)\n",
      "C:\\Users\\jashfaque\\AppData\\Local\\Temp\\ipykernel_18696\\1150252654.py:930: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_data = combined_data.append(df, ignore_index=True)\n",
      "C:\\Users\\jashfaque\\AppData\\Local\\Temp\\ipykernel_18696\\1150252654.py:930: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined_data = combined_data.append(df, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "PATH=\"C:\\\\Users\\\\jashfaque\\\\Desktop\\\\dashboardSoft\\\\chromedriver.exe\"\n",
    "\n",
    "\n",
    "# manager\n",
    "\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "# # Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "\n",
    "# Navigate to the webpage\n",
    "driver.get(\"http://192.168.168.216/premierJute/myPanel/userdefinedreports\")\n",
    "\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "# Find and click the 'From Date' input field to open the calendar\n",
    "from_date_input = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='txtfromdate']\")))\n",
    "from_date_input.click()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Find and click the 'From S1' button\n",
    "from_s1_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='btnFrmS1']\")))\n",
    "from_s1_button.click()\n",
    "\n",
    "# Find and click the 'To Date' input field to open the calendar\n",
    "to_date_input = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='txttodate']\")))\n",
    "to_date_input.click()\n",
    "\n",
    "\n",
    "to_s3_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='btnToS1']\")))\n",
    "driver.execute_script(\"arguments[0].scrollIntoView();\", to_s3_button)\n",
    "driver.execute_script(\"arguments[0].click();\", to_s3_button)\n",
    "\n",
    "# Click on the dropdown\n",
    "dropdown = wait.until(EC.element_to_be_clickable((By.ID, \"select2-body_ddlreportemp-container\")))\n",
    "dropdown.click()\n",
    "\n",
    "\n",
    "# Locate and click the \"Manager\" option\n",
    "manager_option = wait.until(EC.element_to_be_clickable((By.XPATH, \"//li[contains(text(), 'Manager')]\")))\n",
    "manager_option.click()\n",
    "\n",
    "# Click on the \"Load\" button\n",
    "load_button = wait.until(EC.element_to_be_clickable((By.ID, \"Btnsearchid\")))\n",
    "load_button.click()\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "\n",
    "# Extract the HTML content of the page\n",
    "\n",
    "html_code_2 = driver.page_source\n",
    "# Parse the HTML content\n",
    "\n",
    "soup_2 = BeautifulSoup(html_code_2, 'html.parser')\n",
    "\n",
    "# Find the table element\n",
    "table_2 = soup_2.find('table', {'id': 'usertable'})  # Replace 'tblline' with the actual ID of your table\n",
    "\n",
    "# Extract the table headers\n",
    "headers_2 = [th.text.strip() for th in table_2.select('thead th')]\n",
    "\n",
    "# Extract the table rows\n",
    "rows_2 = []\n",
    "for tr in table_2.select('tbody tr'):\n",
    "    row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "    rows_2.append(row_2)\n",
    "\n",
    "# Check if there are any rows in the footer of the table\n",
    "footer_rows_2 = table_2.select('tfoot tr')\n",
    "if footer_rows_2:\n",
    "    # Extract the additional rows from the footer\n",
    "    additional_rows_2 = []\n",
    "    for tr in footer_rows_2:\n",
    "        row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "        additional_rows_2.append(row_2)\n",
    "\n",
    "    # Add the additional rows at the end of the extracted rows\n",
    "    rows_2.extend(additional_rows_2)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df_2 = pd.DataFrame(rows_2, columns=headers_2)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df_2.to_excel('manager_A.xlsx', index=False)\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to the webpage\n",
    "driver.get(\"http://192.168.168.216/premierJute/myPanel/userdefinedreports\")\n",
    "\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "# Find and click the 'From Date' input field to open the calendar\n",
    "from_date_input = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='txtfromdate']\")))\n",
    "from_date_input.click()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Find and click the 'From S1' button\n",
    "from_s1_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='btnFrmS2']\")))\n",
    "from_s1_button.click()\n",
    "\n",
    "# Find and click the 'To Date' input field to open the calendar\n",
    "to_date_input = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='txttodate']\")))\n",
    "to_date_input.click()\n",
    "\n",
    "\n",
    "to_s3_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='btnToS2']\")))\n",
    "driver.execute_script(\"arguments[0].scrollIntoView();\", to_s3_button)\n",
    "driver.execute_script(\"arguments[0].click();\", to_s3_button)\n",
    "\n",
    "# Click on the dropdown\n",
    "dropdown = wait.until(EC.element_to_be_clickable((By.ID, \"select2-body_ddlreportemp-container\")))\n",
    "dropdown.click()\n",
    "\n",
    "\n",
    "# Locate and click the \"Manager\" option\n",
    "manager_option = wait.until(EC.element_to_be_clickable((By.XPATH, \"//li[contains(text(), 'Manager')]\")))\n",
    "manager_option.click()\n",
    "\n",
    "# Click on the \"Load\" button\n",
    "load_button = wait.until(EC.element_to_be_clickable((By.ID, \"Btnsearchid\")))\n",
    "load_button.click()\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "\n",
    "# Extract the HTML content of the page\n",
    "\n",
    "html_code_2 = driver.page_source\n",
    "# Parse the HTML content\n",
    "\n",
    "soup_2 = BeautifulSoup(html_code_2, 'html.parser')\n",
    "\n",
    "# Find the table element\n",
    "table_2 = soup_2.find('table', {'id': 'usertable'})  # Replace 'tblline' with the actual ID of your table\n",
    "\n",
    "# Extract the table headers\n",
    "headers_2 = [th.text.strip() for th in table_2.select('thead th')]\n",
    "\n",
    "# Extract the table rows\n",
    "rows_2 = []\n",
    "for tr in table_2.select('tbody tr'):\n",
    "    row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "    rows_2.append(row_2)\n",
    "\n",
    "# Check if there are any rows in the footer of the table\n",
    "footer_rows_2 = table_2.select('tfoot tr')\n",
    "if footer_rows_2:\n",
    "    # Extract the additional rows from the footer\n",
    "    additional_rows_2 = []\n",
    "    for tr in footer_rows_2:\n",
    "        row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "        additional_rows_2.append(row_2)\n",
    "\n",
    "    # Add the additional rows at the end of the extracted rows\n",
    "    rows_2.extend(additional_rows_2)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df_2 = pd.DataFrame(rows_2, columns=headers_2)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df_2.to_excel('manager_B.xlsx', index=False)\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to the webpage\n",
    "driver.get(\"http://192.168.168.216/premierJute/myPanel/userdefinedreports\")\n",
    "\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "\n",
    "# Find and click the 'From Date' input field to open the calendar\n",
    "from_date_input = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='txtfromdate']\")))\n",
    "from_date_input.click()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Find and click the 'From S1' button\n",
    "from_s1_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='btnFrmS3']\")))\n",
    "from_s1_button.click()\n",
    "\n",
    "# Find and click the 'To Date' input field to open the calendar\n",
    "to_date_input = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='txttodate']\")))\n",
    "to_date_input.click()\n",
    "\n",
    "\n",
    "to_s3_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='btnToS3']\")))\n",
    "driver.execute_script(\"arguments[0].scrollIntoView();\", to_s3_button)\n",
    "driver.execute_script(\"arguments[0].click();\", to_s3_button)\n",
    "\n",
    "# Click on the dropdown\n",
    "dropdown = wait.until(EC.element_to_be_clickable((By.ID, \"select2-body_ddlreportemp-container\")))\n",
    "dropdown.click()\n",
    "\n",
    "\n",
    "# Locate and click the \"Manager\" option\n",
    "manager_option = wait.until(EC.element_to_be_clickable((By.XPATH, \"//li[contains(text(), 'Manager')]\")))\n",
    "manager_option.click()\n",
    "\n",
    "# Click on the \"Load\" button\n",
    "load_button = wait.until(EC.element_to_be_clickable((By.ID, \"Btnsearchid\")))\n",
    "load_button.click()\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "\n",
    "# Extract the HTML content of the page\n",
    "\n",
    "html_code_2 = driver.page_source\n",
    "# Parse the HTML content\n",
    "\n",
    "soup_2 = BeautifulSoup(html_code_2, 'html.parser')\n",
    "\n",
    "# Find the table element\n",
    "table_2 = soup_2.find('table', {'id': 'usertable'})  # Replace 'tblline' with the actual ID of your table\n",
    "\n",
    "# Extract the table headers\n",
    "headers_2 = [th.text.strip() for th in table_2.select('thead th')]\n",
    "\n",
    "# Extract the table rows\n",
    "rows_2 = []\n",
    "for tr in table_2.select('tbody tr'):\n",
    "    row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "    rows_2.append(row_2)\n",
    "\n",
    "# Check if there are any rows in the footer of the table\n",
    "footer_rows_2 = table_2.select('tfoot tr')\n",
    "if footer_rows_2:\n",
    "    # Extract the additional rows from the footer\n",
    "    additional_rows_2 = []\n",
    "    for tr in footer_rows_2:\n",
    "        row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "        additional_rows_2.append(row_2)\n",
    "\n",
    "    # Add the additional rows at the end of the extracted rows\n",
    "    rows_2.extend(additional_rows_2)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df_2 = pd.DataFrame(rows_2, columns=headers_2)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df_2.to_excel('manager_C.xlsx', index=False)\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "\n",
    "# Function to convert columns to numeric except for specified columns\n",
    "def convert_columns_to_numeric(df, exclude_columns):\n",
    "    converted_df = df.copy()\n",
    "    for column in df.columns:\n",
    "        if column not in exclude_columns:\n",
    "            converted_df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "    return converted_df\n",
    "\n",
    "# List of Excel file names\n",
    "excel_files = [\"manager_A.xlsx\", \"manager_B.xlsx\", \"manager_C.xlsx\"]\n",
    "\n",
    "# List of columns to exclude from conversion\n",
    "exclude_columns = [\"Count and Material\"]\n",
    "\n",
    "# Process each Excel file\n",
    "for file in excel_files:\n",
    "    # Read Excel file\n",
    "    df = pd.read_excel(file)\n",
    "    \n",
    "    # Convert columns to numeric\n",
    "    converted_df = convert_columns_to_numeric(df, exclude_columns)\n",
    "    \n",
    "    # Save the modified DataFrame back to the same Excel file\n",
    "    converted_df.to_excel(file, index=False)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# Process each Excel file\n",
    "for file in excel_files:\n",
    "    # Read Excel file\n",
    "    df = pd.read_excel(file)\n",
    "    \n",
    "    # Check if \"AEF %\" column exists in the DataFrame\n",
    "    if \"AEF %\" in df.columns:\n",
    "        # Filter rows based on condition\n",
    "        df = df[df[\"AEF %\"] > 30]\n",
    "        \n",
    "        # Save the filtered DataFrame back to the same Excel file\n",
    "        df.to_excel(file, index=False)\n",
    "    else:\n",
    "        print(f\"Column 'AEF %' not found in the file: {file}. Skipping filtering.\")    \n",
    "    \n",
    "\n",
    "    \n",
    "manager_df_A=pd.read_excel(\"manager_A.xlsx\")\n",
    "\n",
    "running_frame=manager_df_A[\"AEF %\"][:-1].count() #C23\n",
    "avg_efficiency=manager_df_A[\"AEF %\"][:-1].mean()\n",
    "avg_efficiency_percentage = \"{:.2f}%\".format(avg_efficiency)#C24\n",
    "total_idle_spndl=manager_df_A[\"eb idle\"][:-1].sum() #C28\n",
    "total_doffing=manager_df_A[\"doffs\"][:-1].sum() #C30\n",
    "avg_min_doff=manager_df_A[\"min/doff\"][:-1].mean() #C31\n",
    "stop_minutes=manager_df_A[\"Total M/c Stop time\"][:-1].sum() #C32\n",
    "total_end_br=manager_df_A[\"eb total\"][:-1].sum() #C33\n",
    "                                     \n",
    "\n",
    "                                    \n",
    "# Load the workbook\n",
    "workbook = load_workbook(\"UltimoJJ analysis report.xlsx\")\n",
    "\n",
    "# Select the desired sheet (e.g., Summary)\n",
    "sheet = workbook[\"Summary\"]\n",
    "\n",
    "# Check if manager A's data is present\n",
    "manager_a_present = True\n",
    "try:\n",
    "    manager_df_a = pd.read_excel(\"manager_A.xlsx\")\n",
    "except FileNotFoundError:\n",
    "    manager_a_present = False\n",
    "\n",
    "# Check if manager B's data is present\n",
    "manager_b_present = True\n",
    "try:\n",
    "    manager_df_b = pd.read_excel(\"manager_B.xlsx\")\n",
    "except FileNotFoundError:\n",
    "    manager_b_present = False\n",
    "\n",
    "# Check if manager C's data is present\n",
    "manager_c_present = True\n",
    "try:\n",
    "    manager_df_c = pd.read_excel(\"manager_C.xlsx\")\n",
    "except FileNotFoundError:\n",
    "    manager_c_present = False\n",
    "\n",
    "# Write data for manager A if only manager A's data is present\n",
    "if manager_a_present and not manager_b_present and not manager_c_present:\n",
    "    running_frame_a = manager_df_a[\"AEF %\"][:-1].count()\n",
    "    avg_efficiency_a = manager_df_a[\"AEF %\"][:-1].mean()\n",
    "    avg_efficiency_percentage_a = \"{:.2f}%\".format(avg_efficiency_a)\n",
    "    total_idle_spndl_a = manager_df_a[\"eb idle\"][:-1].sum()\n",
    "    total_doffing_a = manager_df_a[\"doffs\"][:-1].sum()\n",
    "    avg_min_doff_a = manager_df_a[\"min/doff\"][:-1].mean()\n",
    "    stop_minutes_a = manager_df_a[\"Total M/c Stop time\"][:-1].sum()\n",
    "    total_end_br_a = manager_df_a[\"eb total\"][:-1].sum()\n",
    "\n",
    "    sheet[\"C23\"] = running_frame_a\n",
    "    sheet[\"C24\"] = avg_efficiency_percentage_a\n",
    "    sheet[\"C28\"] = total_idle_spndl_a\n",
    "    sheet[\"C30\"] = total_doffing_a\n",
    "    sheet[\"C31\"] = avg_min_doff_a\n",
    "    sheet[\"C32\"] = stop_minutes_a\n",
    "    sheet[\"C33\"] = total_end_br_a\n",
    "\n",
    "# Write data for manager B if only manager B's data is present\n",
    "elif manager_b_present and not manager_a_present and not manager_c_present:\n",
    "    running_frame_b = manager_df_b[\"AEF %\"][:-1].count()\n",
    "    avg_efficiency_b = manager_df_b[\"AEF %\"][:-1].mean()\n",
    "    avg_efficiency_percentage_b = \"{:.2f}%\".format(avg_efficiency_b)\n",
    "    total_idle_spndl_b = manager_df_b[\"eb idle\"][:-1].sum()\n",
    "    total_doffing_b = manager_df_b[\"doffs\"][:-1].sum()\n",
    "    avg_min_doff_b = manager_df_b[\"min/doff\"][:-1].mean()\n",
    "    stop_minutes_b = manager_df_b[\"Total M/c Stop time\"][:-1].sum()\n",
    "    total_end_br_b = manager_df_b[\"eb total\"][:-1].sum()\n",
    "\n",
    "    sheet[\"F23\"] = running_frame_b\n",
    "    sheet[\"F24\"] = avg_efficiency_percentage_b\n",
    "    sheet[\"F28\"] = total_idle_spndl_b\n",
    "    sheet[\"F30\"] = total_doffing_b\n",
    "    sheet[\"F31\"] = avg_min_doff_b\n",
    "    sheet[\"F32\"] = stop_minutes_b\n",
    "    sheet[\"F33\"] = total_end_br_b\n",
    "\n",
    "# Write data for manager C if only manager C's data is present\n",
    "elif manager_c_present and not manager_a_present and not manager_b_present:\n",
    "    running_frame_c = manager_df_c[\"AEF %\"][:-1].count()\n",
    "    avg_efficiency_c = manager_df_c[\"AEF %\"][:-1].mean()\n",
    "    avg_efficiency_percentage_c = \"{:.2f}%\".format(avg_efficiency_c)\n",
    "    total_idle_spndl_c = manager_df_c[\"eb idle\"][:-1].sum()\n",
    "    total_doffing_c = manager_df_c[\"doffs\"][:-1].sum()\n",
    "    avg_min_doff_c = manager_df_c[\"min/doff\"][:-1].mean()\n",
    "    stop_minutes_c = manager_df_c[\"Total M/c Stop time\"][:-1].sum()\n",
    "    total_end_br_c = manager_df_c[\"eb total\"][:-1].sum()\n",
    "\n",
    "    sheet[\"I23\"] = running_frame_c\n",
    "    sheet[\"I24\"] = avg_efficiency_percentage_c\n",
    "    sheet[\"I28\"] = total_idle_spndl_c\n",
    "    sheet[\"I30\"] = total_doffing_c\n",
    "    sheet[\"I31\"] = avg_min_doff_c\n",
    "    sheet[\"I32\"] = stop_minutes_c\n",
    "    sheet[\"I33\"] = total_end_br_c\n",
    "\n",
    "    \n",
    "elif manager_a_present and manager_b_present:\n",
    "    # Write manager_A data\n",
    "    running_frame_a = manager_df_A[\"AEF %\"][:-1].count()\n",
    "    avg_efficiency_a = manager_df_A[\"AEF %\"][:-1].mean()\n",
    "    avg_efficiency_percentage_a = \"{:.2f}%\".format(avg_efficiency_a)\n",
    "    total_idle_spndl_a = manager_df_A[\"eb idle\"][:-1].sum()\n",
    "    total_doffing_a = manager_df_A[\"doffs\"][:-1].sum()\n",
    "    avg_min_doff_a = manager_df_A[\"min/doff\"][:-1].mean()\n",
    "    stop_minutes_a = manager_df_A[\"Total M/c Stop time\"][:-1].sum()\n",
    "    total_end_br_a = manager_df_A[\"eb total\"][:-1].sum()\n",
    "\n",
    "    # Write the data to specific cells for manager_A\n",
    "    sheet[\"C23\"] = running_frame_a\n",
    "    sheet[\"C24\"] = avg_efficiency_percentage_a\n",
    "    sheet[\"C28\"] = total_idle_spndl_a\n",
    "    sheet[\"C30\"] = total_doffing_a\n",
    "    sheet[\"C31\"] = avg_min_doff_a\n",
    "    sheet[\"C32\"] = stop_minutes_a\n",
    "    sheet[\"C33\"] = total_end_br_a\n",
    "\n",
    "    # Write manager_B data\n",
    "    running_frame_b = manager_df_B[\"AEF %\"][:-1].count()\n",
    "    avg_efficiency_b = manager_df_B[\"AEF %\"][:-1].mean()\n",
    "    avg_efficiency_percentage_b = \"{:.2f}%\".format(avg_efficiency_b)\n",
    "    total_idle_spndl_b = manager_df_B[\"eb idle\"][:-1].sum()\n",
    "    total_doffing_b = manager_df_B[\"doffs\"][:-1].sum()\n",
    "    avg_min_doff_b = manager_df_B[\"min/doff\"][:-1].mean()\n",
    "    stop_minutes_b = manager_df_B[\"Total M/c Stop time\"][:-1].sum()\n",
    "    total_end_br_b = manager_df_B[\"eb total\"][:-1].sum()\n",
    "\n",
    "    # Write the data to specific cells for manager_B\n",
    "    sheet[\"F23\"] = running_frame_b\n",
    "    sheet[\"F24\"] = avg_efficiency_percentage_b\n",
    "    sheet[\"F28\"] = total_idle_spndl_b\n",
    "    sheet[\"F30\"] = total_doffing_b\n",
    "    sheet[\"F31\"] = avg_min_doff_b\n",
    "    sheet[\"F32\"] = stop_minutes_b\n",
    "    sheet[\"F33\"] = total_end_br_b\n",
    "\n",
    "\n",
    "elif manager_b_present and manager_c_present:\n",
    "\n",
    "    # Write manager_B data\n",
    "    running_frame_b = manager_df_B[\"AEF %\"][:-1].count()\n",
    "    avg_efficiency_b = manager_df_B[\"AEF %\"][:-1].mean()\n",
    "    avg_efficiency_percentage_b = \"{:.2f}%\".format(avg_efficiency_b)\n",
    "    total_idle_spndl_b = manager_df_B[\"eb idle\"][:-1].sum()\n",
    "    total_doffing_b = manager_df_B[\"doffs\"][:-1].sum()\n",
    "    avg_min_doff_b = manager_df_B[\"min/doff\"][:-1].mean()\n",
    "    stop_minutes_b = manager_df_B[\"Total M/c Stop time\"][:-1].sum()\n",
    "    total_end_br_b = manager_df_B[\"eb total\"][:-1].sum()\n",
    "\n",
    "    # Write the data to specific cells for manager_B\n",
    "    sheet[\"F23\"] = running_frame_b\n",
    "    sheet[\"F24\"] = avg_efficiency_percentage_b\n",
    "    sheet[\"F28\"] = total_idle_spndl_b\n",
    "    sheet[\"F30\"] = total_doffing_b\n",
    "    sheet[\"F31\"] = avg_min_doff_b\n",
    "    sheet[\"F32\"] = stop_minutes_b\n",
    "    sheet[\"F33\"] = total_end_br_b\n",
    "    \n",
    "    running_frame_c = manager_df_c[\"AEF %\"][:-1].count()\n",
    "    avg_efficiency_c = manager_df_c[\"AEF %\"][:-1].mean()\n",
    "    avg_efficiency_percentage_c = \"{:.2f}%\".format(avg_efficiency_c)\n",
    "    total_idle_spndl_c = manager_df_c[\"eb idle\"][:-1].sum()\n",
    "    total_doffing_c = manager_df_c[\"doffs\"][:-1].sum()\n",
    "    avg_min_doff_c = manager_df_c[\"min/doff\"][:-1].mean()\n",
    "    stop_minutes_c = manager_df_c[\"Total M/c Stop time\"][:-1].sum()\n",
    "    total_end_br_c = manager_df_c[\"eb total\"][:-1].sum()\n",
    "\n",
    "    sheet[\"I23\"] = running_frame_c\n",
    "    sheet[\"I24\"] = avg_efficiency_percentage_c\n",
    "    sheet[\"I28\"] = total_idle_spndl_c\n",
    "    sheet[\"I30\"] = total_doffing_c\n",
    "    sheet[\"I31\"] = avg_min_doff_c\n",
    "    sheet[\"I32\"] = stop_minutes_c\n",
    "    sheet[\"I33\"] = total_end_br_c\n",
    "\n",
    "elif manager_b_present and manager_c_present:\n",
    "\n",
    "    running_frame_a = manager_df_a[\"AEF %\"][:-1].count()\n",
    "    avg_efficiency_a = manager_df_a[\"AEF %\"][:-1].mean()\n",
    "    avg_efficiency_percentage_a = \"{:.2f}%\".format(avg_efficiency_a)\n",
    "    total_idle_spndl_a = manager_df_a[\"eb idle\"][:-1].sum()\n",
    "    total_doffing_a = manager_df_a[\"doffs\"][:-1].sum()\n",
    "    avg_min_doff_a = manager_df_a[\"min/doff\"][:-1].mean()\n",
    "    stop_minutes_a = manager_df_a[\"Total M/c Stop time\"][:-1].sum()\n",
    "    total_end_br_a = manager_df_a[\"eb total\"][:-1].sum()\n",
    "\n",
    "    sheet[\"C23\"] = running_frame_a\n",
    "    sheet[\"C24\"] = avg_efficiency_percentage_a\n",
    "    sheet[\"C28\"] = total_idle_spndl_a\n",
    "    sheet[\"C30\"] = total_doffing_a\n",
    "    sheet[\"C31\"] = avg_min_doff_a\n",
    "    sheet[\"C32\"] = stop_minutes_a\n",
    "    sheet[\"C33\"] = total_end_br_a\n",
    "    \n",
    "    running_frame_c = manager_df_c[\"AEF %\"][:-1].count()\n",
    "    avg_efficiency_c = manager_df_c[\"AEF %\"][:-1].mean()\n",
    "    avg_efficiency_percentage_c = \"{:.2f}%\".format(avg_efficiency_c)\n",
    "    total_idle_spndl_c = manager_df_c[\"eb idle\"][:-1].sum()\n",
    "    total_doffing_c = manager_df_c[\"doffs\"][:-1].sum()\n",
    "    avg_min_doff_c = manager_df_c[\"min/doff\"][:-1].mean()\n",
    "    stop_minutes_c = manager_df_c[\"Total M/c Stop time\"][:-1].sum()\n",
    "    total_end_br_c = manager_df_c[\"eb total\"][:-1].sum()\n",
    "\n",
    "    sheet[\"I23\"] = running_frame_c\n",
    "    sheet[\"I24\"] = avg_efficiency_percentage_c\n",
    "    sheet[\"I28\"] = total_idle_spndl_c\n",
    "    sheet[\"I30\"] = total_doffing_c\n",
    "    sheet[\"I31\"] = avg_min_doff_c\n",
    "    sheet[\"I32\"] = stop_minutes_c\n",
    "    sheet[\"I33\"] = total_end_br_c\n",
    "\n",
    "# Write data for all managers if data for all managers is present\n",
    "elif manager_a_present and manager_b_present and manager_c_present:\n",
    "    running_frame_a = manager_df_a[\"AEF %\"][:-1].count()\n",
    "    avg_efficiency_a = manager_df_a[\"AEF %\"][:-1].mean()\n",
    "    avg_efficiency_percentage_a = \"{:.2f}%\".format(avg_efficiency_a)\n",
    "    total_idle_spndl_a = manager_df_a[\"eb idle\"][:-1].sum()\n",
    "    total_doffing_a = manager_df_a[\"doffs\"][:-1].sum()\n",
    "    avg_min_doff_a = manager_df_a[\"min/doff\"][:-1].mean()\n",
    "    stop_minutes_a = manager_df_a[\"Total M/c Stop time\"][:-1].sum()\n",
    "    total_end_br_a = manager_df_a[\"eb total\"][:-1].sum()\n",
    "\n",
    "    sheet[\"C23\"] = running_frame_a\n",
    "    sheet[\"C24\"] = avg_efficiency_percentage_a\n",
    "    sheet[\"C28\"] = total_idle_spndl_a\n",
    "    sheet[\"C30\"] = total_doffing_a\n",
    "    sheet[\"C31\"] = avg_min_doff_a\n",
    "    sheet[\"C32\"] = stop_minutes_a\n",
    "    sheet[\"C33\"] = total_end_br_a\n",
    "\n",
    "    running_frame_b = manager_df_b[\"AEF %\"][:-1].count()\n",
    "    avg_efficiency_b = manager_df_b[\"AEF %\"][:-1].mean()\n",
    "    avg_efficiency_percentage_b = \"{:.2f}%\".format(avg_efficiency_b)\n",
    "    total_idle_spndl_b = manager_df_b[\"eb idle\"][:-1].sum()\n",
    "    total_doffing_b = manager_df_b[\"doffs\"][:-1].sum()\n",
    "    avg_min_doff_b = manager_df_b[\"min/doff\"][:-1].mean()\n",
    "    stop_minutes_b = manager_df_b[\"Total M/c Stop time\"][:-1].sum()\n",
    "    total_end_br_b = manager_df_b[\"eb total\"][:-1].sum()\n",
    "\n",
    "    sheet[\"F23\"] = running_frame_b\n",
    "    sheet[\"F24\"] = avg_efficiency_percentage_b\n",
    "    sheet[\"F28\"] = total_idle_spndl_b\n",
    "    sheet[\"F30\"] = total_doffing_b\n",
    "    sheet[\"F31\"] = avg_min_doff_b\n",
    "    sheet[\"F32\"] = stop_minutes_b\n",
    "    sheet[\"F33\"] = total_end_br_b\n",
    "\n",
    "    running_frame_c = manager_df_c[\"AEF %\"][:-1].count()\n",
    "    avg_efficiency_c = manager_df_c[\"AEF %\"][:-1].mean()\n",
    "    avg_efficiency_percentage_c = \"{:.2f}%\".format(avg_efficiency_c)\n",
    "    total_idle_spndl_c = manager_df_c[\"eb idle\"][:-1].sum()\n",
    "    total_doffing_c = manager_df_c[\"doffs\"][:-1].sum()\n",
    "    avg_min_doff_c = manager_df_c[\"min/doff\"][:-1].mean()\n",
    "    stop_minutes_c = manager_df_c[\"Total M/c Stop time\"][:-1].sum()\n",
    "    total_end_br_c = manager_df_c[\"eb total\"][:-1].sum()\n",
    "\n",
    "    sheet[\"I23\"] = running_frame_c\n",
    "    sheet[\"I24\"] = avg_efficiency_percentage_c\n",
    "    sheet[\"I28\"] = total_idle_spndl_c\n",
    "    sheet[\"I30\"] = total_doffing_c\n",
    "    sheet[\"I31\"] = avg_min_doff_c\n",
    "    sheet[\"I32\"] = stop_minutes_c\n",
    "    sheet[\"I33\"] = total_end_br_c\n",
    "    \n",
    "\n",
    "\n",
    "# Save the modified workbook\n",
    "workbook.save(\"UltimoJJ analysis report.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "# breakage\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to the webpage\n",
    "driver.get(\"http://192.168.168.216/premierJute/myPanel/userdefinedreports\")\n",
    "\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "# Find and select the input field with ID \"txtfromdate\"\n",
    "input_field = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='txtfromdate']\")))\n",
    "input_field.click()\n",
    "\n",
    "\n",
    "# Find and click the button with ID \"btnFrmS1\"\n",
    "button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='btnFrmS1']\")))\n",
    "driver.execute_script(\"arguments[0].click();\", button)\n",
    "\n",
    "\n",
    "# Find and click the input field with ID \"txttodate\"\n",
    "input_field = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='txttodate']\")))\n",
    "input_field.click()\n",
    "\n",
    "# Find and click the button with ID \"btnToS3\"\n",
    "button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='btnToS1']\")))\n",
    "button.click()\n",
    "\n",
    "\n",
    "\n",
    "# Wait for a brief period before clicking the next button\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Click on the dropdown\n",
    "dropdown = wait.until(EC.element_to_be_clickable((By.ID, \"select2-body_ddlreportemp-container\")))\n",
    "dropdown.click()\n",
    "\n",
    "\n",
    "# Locate and click the \"Breakage\" option\n",
    "manager_option = wait.until(EC.element_to_be_clickable((By.XPATH, \"//li[contains(text(), 'Breakage')]\")))\n",
    "manager_option.click()\n",
    "\n",
    "# Find the \"Load\" button element\n",
    "load_button_1 = wait.until(EC.element_to_be_clickable((By.ID, \"Btnsearchid\")))\n",
    "\n",
    "# Click the \"Load\" button\n",
    "load_button_1.click()\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "html_code_br = driver.page_source\n",
    "# Parse the HTML content\n",
    "\n",
    "soup_br = BeautifulSoup(html_code_br, 'html.parser')\n",
    "\n",
    "# Find the table element\n",
    "table_br = soup_br.find('table', {'id': 'usertable'})  # Replace 'tblline' with the actual ID of your table\n",
    "\n",
    "# Extract the table headers\n",
    "headers_br = [th.text.strip() for th in table_br.select('thead th')]\n",
    "\n",
    "# Extract the table rows\n",
    "rows_br = []\n",
    "for tr in table_br.select('tbody tr'):\n",
    "    row_br = [td.text.strip() for td in tr.select('td')]\n",
    "    rows_br.append(row_br)\n",
    "\n",
    "# Check if there are any rows in the footer of the table\n",
    "footer_rows_br = table_br.select('tfoot tr')\n",
    "if footer_rows_br:\n",
    "    # Extract the additional rows from the footer\n",
    "    additional_rows_br = []\n",
    "    for tr in footer_rows_br:\n",
    "        row_br = [td.text.strip() for td in tr.select('td')]\n",
    "        additional_rows_br.append(row_br)\n",
    "\n",
    "    # Add the additional rows at the end of the extracted rows\n",
    "    rows_br.extend(additional_rows_br)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df_br = pd.DataFrame(rows_br, columns=headers_br)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df_br.to_excel('breakage_A.xlsx', index=False)\n",
    "\n",
    "\n",
    "\n",
    "time.sleep(10)\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to the webpage\n",
    "driver.get(\"http://192.168.168.216/premierJute/myPanel/userdefinedreports\")\n",
    "\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "\n",
    "# Find and select the input field with ID \"txtfromdate\"\n",
    "input_field = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='txtfromdate']\")))\n",
    "input_field.click()\n",
    "\n",
    "\n",
    "# Find and click the button with ID \"btnFrmS1\"\n",
    "button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='btnFrmS2']\")))\n",
    "driver.execute_script(\"arguments[0].click();\", button)\n",
    "\n",
    "\n",
    "# Find and click the input field with ID \"txttodate\"\n",
    "input_field = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='txttodate']\")))\n",
    "input_field.click()\n",
    "\n",
    "# Find and click the button with ID \"btnToS3\"\n",
    "button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='btnToS2']\")))\n",
    "button.click()\n",
    "\n",
    "# Wait for a brief period before clicking the next button\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Click on the dropdown\n",
    "dropdown = wait.until(EC.element_to_be_clickable((By.ID, \"select2-body_ddlreportemp-container\")))\n",
    "dropdown.click()\n",
    "\n",
    "\n",
    "# Locate and click the \"Breakage\" option\n",
    "manager_option = wait.until(EC.element_to_be_clickable((By.XPATH, \"//li[contains(text(), 'Breakage')]\")))\n",
    "manager_option.click()\n",
    "\n",
    "# Find the \"Load\" button element\n",
    "load_button_1 = wait.until(EC.element_to_be_clickable((By.ID, \"Btnsearchid\")))\n",
    "\n",
    "# Click the \"Load\" button\n",
    "load_button_1.click()\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "html_code_br = driver.page_source\n",
    "# Parse the HTML content\n",
    "\n",
    "soup_br = BeautifulSoup(html_code_br, 'html.parser')\n",
    "\n",
    "# Find the table element\n",
    "table_br = soup_br.find('table', {'id': 'usertable'})  # Replace 'tblline' with the actual ID of your table\n",
    "\n",
    "# Extract the table headers\n",
    "headers_br = [th.text.strip() for th in table_br.select('thead th')]\n",
    "\n",
    "# Extract the table rows\n",
    "rows_br = []\n",
    "for tr in table_br.select('tbody tr'):\n",
    "    row_br = [td.text.strip() for td in tr.select('td')]\n",
    "    rows_br.append(row_br)\n",
    "\n",
    "# Check if there are any rows in the footer of the table\n",
    "footer_rows_br = table_br.select('tfoot tr')\n",
    "if footer_rows_br:\n",
    "    # Extract the additional rows from the footer\n",
    "    additional_rows_br = []\n",
    "    for tr in footer_rows_br:\n",
    "        row_br = [td.text.strip() for td in tr.select('td')]\n",
    "        additional_rows_br.append(row_br)\n",
    "\n",
    "    # Add the additional rows at the end of the extracted rows\n",
    "    rows_br.extend(additional_rows_br)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df_br = pd.DataFrame(rows_br, columns=headers_br)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df_br.to_excel('breakage_B.xlsx', index=False)\n",
    "\n",
    "time.sleep(10)\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to the webpage\n",
    "driver.get(\"http://192.168.168.216/premierJute/myPanel/userdefinedreports\")\n",
    "\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "\n",
    "# Find and select the input field with ID \"txtfromdate\"\n",
    "input_field = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='txtfromdate']\")))\n",
    "input_field.click()\n",
    "\n",
    "\n",
    "# Find and click the button with ID \"btnFrmS1\"\n",
    "button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='btnFrmS3']\")))\n",
    "driver.execute_script(\"arguments[0].click();\", button)\n",
    "\n",
    "\n",
    "# Find and click the input field with ID \"txttodate\"\n",
    "input_field = wait.until(EC.element_to_be_clickable((By.XPATH, \"//input[@id='txttodate']\")))\n",
    "input_field.click()\n",
    "\n",
    "# Find and click the button with ID \"btnToS3\"\n",
    "button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[@id='btnToS3']\")))\n",
    "button.click()\n",
    "\n",
    "# Wait for a brief period before clicking the next button\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Click on the dropdown\n",
    "dropdown = wait.until(EC.element_to_be_clickable((By.ID, \"select2-body_ddlreportemp-container\")))\n",
    "dropdown.click()\n",
    "\n",
    "\n",
    "# Locate and click the \"Breakage\" option\n",
    "manager_option = wait.until(EC.element_to_be_clickable((By.XPATH, \"//li[contains(text(), 'Breakage')]\")))\n",
    "manager_option.click()\n",
    "\n",
    "# Find the \"Load\" button element\n",
    "load_button_1 = wait.until(EC.element_to_be_clickable((By.ID, \"Btnsearchid\")))\n",
    "\n",
    "# Click the \"Load\" button\n",
    "load_button_1.click()\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "html_code_br = driver.page_source\n",
    "# Parse the HTML content\n",
    "\n",
    "soup_br = BeautifulSoup(html_code_br, 'html.parser')\n",
    "\n",
    "# Find the table element\n",
    "table_br = soup_br.find('table', {'id': 'usertable'})  # Replace 'tblline' with the actual ID of your table\n",
    "\n",
    "# Extract the table headers\n",
    "headers_br = [th.text.strip() for th in table_br.select('thead th')]\n",
    "\n",
    "# Extract the table rows\n",
    "rows_br = []\n",
    "for tr in table_br.select('tbody tr'):\n",
    "    row_br = [td.text.strip() for td in tr.select('td')]\n",
    "    rows_br.append(row_br)\n",
    "\n",
    "# Check if there are any rows in the footer of the table\n",
    "footer_rows_br = table_br.select('tfoot tr')\n",
    "if footer_rows_br:\n",
    "    # Extract the additional rows from the footer\n",
    "    additional_rows_br = []\n",
    "    for tr in footer_rows_br:\n",
    "        row_br = [td.text.strip() for td in tr.select('td')]\n",
    "        additional_rows_br.append(row_br)\n",
    "\n",
    "    # Add the additional rows at the end of the extracted rows\n",
    "    rows_br.extend(additional_rows_br)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df_br = pd.DataFrame(rows_br, columns=headers_br)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df_br.to_excel('breakage_C.xlsx', index=False)\n",
    "\n",
    "\n",
    "\n",
    "time.sleep(10)\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to the webpage\n",
    "driver.get(\"http://192.168.168.216/premierJute/myPanel/userdefinedreports\")\n",
    "\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "\n",
    "# Function to convert columns to numeric except for specified columns\n",
    "def convert_columns_to_numeric(df, exclude_columns):\n",
    "    converted_df = df.copy()\n",
    "    for column in df.columns:\n",
    "        if column not in exclude_columns:\n",
    "            converted_df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "    return converted_df\n",
    "\n",
    "# List of Excel file names\n",
    "excel_files = [\"breakage_A.xlsx\", \"breakage_B.xlsx\", \"breakage_C.xlsx\"]\n",
    "\n",
    "# List of columns to exclude from conversion\n",
    "exclude_columns = [\"Count and Material\"]\n",
    "\n",
    "# Process each Excel file\n",
    "for file in excel_files:\n",
    "    # Read Excel file\n",
    "    df = pd.read_excel(file)\n",
    "    \n",
    "    # Convert columns to numeric\n",
    "    converted_df = convert_columns_to_numeric(df, exclude_columns)\n",
    "    \n",
    "    # Save the modified DataFrame back to the same Excel file\n",
    "    converted_df.to_excel(file, index=False)\n",
    "    \n",
    "    \n",
    "\n",
    "#import pandas as pd\n",
    "\n",
    "# List of file names\n",
    "file_names = ['breakage_A.xlsx', 'breakage_B.xlsx', 'breakage_C.xlsx']\n",
    "\n",
    "# Read the previous data from convt_break.xlsx if it exists\n",
    "try:\n",
    "    previous_data = pd.read_excel('convt_break.xlsx')\n",
    "except FileNotFoundError:\n",
    "    previous_data = pd.DataFrame()\n",
    "\n",
    "# Initialize an empty DataFrame to store the combined data\n",
    "combined_data = previous_data.copy()\n",
    "\n",
    "# Iterate over the file names and read each Excel file\n",
    "for file_name in file_names:\n",
    "    # Read the Excel file into a DataFrame\n",
    "    df = pd.read_excel(file_name)\n",
    "\n",
    "    # Exclude the last row of the DataFrame\n",
    "    df = df.iloc[:-1]\n",
    "\n",
    "    # Append the data to the combined DataFrame\n",
    "    combined_data = combined_data.append(df, ignore_index=True)\n",
    "\n",
    "# Group the combined data by M/c No. and calculate the sum of 'eb_total' and mean of 'AEF %'\n",
    "grouped_data = combined_data.groupby('M/c No.').agg({'eb total': 'sum', 'AEF %': 'mean'}).reset_index()\n",
    "\n",
    "# Save the grouped data to convt_break.xlsx\n",
    "grouped_data.to_excel('convt_break.xlsx', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a new instance of the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "# Navigate to the web page\n",
    "driver.get(\"http://192.168.168.216/premierJute/myPanel/userdefinedreports\")\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "\n",
    "\n",
    "# Find and input the 'From Date'\n",
    "from_date_input = driver.find_element(By.XPATH, \"//input[@id='txtfromdate']\")\n",
    "from_date_input.click()\n",
    "\n",
    "# Click on the 'From' button\n",
    "from_button = driver.find_element(By.XPATH, \"//button[@id='btnFrmS1']\")\n",
    "from_button.click()\n",
    "\n",
    "# Find and input the 'To Date'\n",
    "to_date_input = driver.find_element(By.XPATH, \"//input[@id='txttodate']\")\n",
    "to_date_input.click()\n",
    "\n",
    "# Click on the 'To' button\n",
    "to_button = driver.find_element(By.XPATH, \"//button[@id='btnToS1']\")\n",
    "to_button.click()\n",
    "\n",
    "\n",
    "# Find and click on the dropdown\n",
    "dropdown = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, \"//span[@id='select2-body_ddlreportemp-container']\"))\n",
    ")\n",
    "dropdown.click()\n",
    "\n",
    "time.sleep(5)\n",
    "# Locate and click the \"Manager\" option\n",
    "kg_option = wait.until(EC.element_to_be_clickable((By.XPATH, \"//li[contains(text(), 'Kg')]\")))\n",
    "kg_option.click()\n",
    "\n",
    "\n",
    "# Click on the search button\n",
    "search_button = driver.find_element(By.XPATH, \"//button[@id='Btnsearchid']\")\n",
    "search_button.click()\n",
    "time.sleep(10)\n",
    "\n",
    "\n",
    "\n",
    "html_code_2 = driver.page_source\n",
    "# Parse the HTML content\n",
    "\n",
    "soup_2 = BeautifulSoup(html_code_2, 'html.parser')\n",
    "\n",
    "# Find the table element\n",
    "table_2 = soup_2.find('table', {'id': 'usertable'})  # Replace 'tblline' with the actual ID of your table\n",
    "\n",
    "# Extract the table headers\n",
    "headers_2 = [th.text.strip() for th in table_2.select('thead th')]\n",
    "\n",
    "# Extract the table rows\n",
    "rows_2 = []\n",
    "for tr in table_2.select('tbody tr'):\n",
    "    row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "    rows_2.append(row_2)\n",
    "\n",
    "# Check if there are any rows in the footer of the table\n",
    "footer_rows_2 = table_2.select('tfoot tr')\n",
    "if footer_rows_2:\n",
    "    # Extract the additional rows from the footer\n",
    "    additional_rows_2 = []\n",
    "    for tr in footer_rows_2:\n",
    "        row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "        additional_rows_2.append(row_2)\n",
    "\n",
    "    # Add the additional rows at the end of the extracted rows\n",
    "    rows_2.extend(additional_rows_2)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df_2 = pd.DataFrame(rows_2, columns=headers_2)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df_2.to_excel('Kg_A.xlsx', index=False)\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "\n",
    "# Set up the Selenium webdriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "wait = WebDriverWait(driver, 20)\n",
    "# Navigate to the web page\n",
    "driver.get(\"http://192.168.168.216/premierJute/myPanel/userdefinedreports\")\n",
    "\n",
    "# Find and input the 'From Date'\n",
    "from_date_input = driver.find_element(By.XPATH, \"//input[@id='txtfromdate']\")\n",
    "from_date_input.click()\n",
    "\n",
    "# Click on the 'From' button\n",
    "from_button = driver.find_element(By.XPATH, \"//button[@id='btnFrmS2']\")\n",
    "from_button.click()\n",
    "\n",
    "# Find and input the 'To Date'\n",
    "to_date_input = driver.find_element(By.XPATH, \"//input[@id='txttodate']\")\n",
    "to_date_input.click()\n",
    "\n",
    "# Click on the 'To' button\n",
    "to_button = driver.find_element(By.XPATH, \"//button[@id='btnToS2']\")\n",
    "to_button.click()\n",
    "\n",
    "\n",
    "# Find and click on the dropdown\n",
    "dropdown = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, \"//span[@id='select2-body_ddlreportemp-container']\"))\n",
    ")\n",
    "dropdown.click()\n",
    "\n",
    "time.sleep(5)\n",
    "# Locate and click the \"Manager\" option\n",
    "kg_option = wait.until(EC.element_to_be_clickable((By.XPATH, \"//li[contains(text(), 'Kg')]\")))\n",
    "kg_option.click()\n",
    "\n",
    "\n",
    "# Click on the search button\n",
    "search_button = driver.find_element(By.XPATH, \"//button[@id='Btnsearchid']\")\n",
    "search_button.click()\n",
    "time.sleep(10)\n",
    "\n",
    "\n",
    "\n",
    "html_code_2 = driver.page_source\n",
    "# Parse the HTML content\n",
    "\n",
    "soup_2 = BeautifulSoup(html_code_2, 'html.parser')\n",
    "\n",
    "# Find the table element\n",
    "table_2 = soup_2.find('table', {'id': 'usertable'})  # Replace 'tblline' with the actual ID of your table\n",
    "\n",
    "# Extract the table headers\n",
    "headers_2 = [th.text.strip() for th in table_2.select('thead th')]\n",
    "\n",
    "# Extract the table rows\n",
    "rows_2 = []\n",
    "for tr in table_2.select('tbody tr'):\n",
    "    row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "    rows_2.append(row_2)\n",
    "\n",
    "# Check if there are any rows in the footer of the table\n",
    "footer_rows_2 = table_2.select('tfoot tr')\n",
    "if footer_rows_2:\n",
    "    # Extract the additional rows from the footer\n",
    "    additional_rows_2 = []\n",
    "    for tr in footer_rows_2:\n",
    "        row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "        additional_rows_2.append(row_2)\n",
    "\n",
    "    # Add the additional rows at the end of the extracted rows\n",
    "    rows_2.extend(additional_rows_2)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df_2 = pd.DataFrame(rows_2, columns=headers_2)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df_2.to_excel('Kg_B.xlsx', index=False)\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "# Set up the Selenium webdriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "wait = WebDriverWait(driver, 20)\n",
    "# Navigate to the web page\n",
    "driver.get(\"http://192.168.168.216/premierJute/myPanel/userdefinedreports\")\n",
    "\n",
    "# Find and input the 'From Date'\n",
    "from_date_input = driver.find_element(By.XPATH, \"//input[@id='txtfromdate']\")\n",
    "from_date_input.click()\n",
    "\n",
    "# Click on the 'From' button\n",
    "from_button = driver.find_element(By.XPATH, \"//button[@id='btnFrmS3']\")\n",
    "from_button.click()\n",
    "\n",
    "# Find and input the 'To Date'\n",
    "to_date_input = driver.find_element(By.XPATH, \"//input[@id='txttodate']\")\n",
    "to_date_input.click()\n",
    "\n",
    "# Click on the 'To' button\n",
    "to_button = driver.find_element(By.XPATH, \"//button[@id='btnToS3']\")\n",
    "to_button.click()\n",
    "\n",
    "\n",
    "# Find and click on the dropdown\n",
    "dropdown = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, \"//span[@id='select2-body_ddlreportemp-container']\"))\n",
    ")\n",
    "dropdown.click()\n",
    "\n",
    "time.sleep(5)\n",
    "# Locate and click the \"Manager\" option\n",
    "kg_option = wait.until(EC.element_to_be_clickable((By.XPATH, \"//li[contains(text(), 'Kg')]\")))\n",
    "kg_option.click()\n",
    "\n",
    "\n",
    "# Click on the search button\n",
    "search_button = driver.find_element(By.XPATH, \"//button[@id='Btnsearchid']\")\n",
    "search_button.click()\n",
    "time.sleep(10)\n",
    "\n",
    "\n",
    "\n",
    "html_code_2 = driver.page_source\n",
    "# Parse the HTML content\n",
    "\n",
    "soup_2 = BeautifulSoup(html_code_2, 'html.parser')\n",
    "\n",
    "# Find the table element\n",
    "table_2 = soup_2.find('table', {'id': 'usertable'})  # Replace 'tblline' with the actual ID of your table\n",
    "\n",
    "# Extract the table headers\n",
    "headers_2 = [th.text.strip() for th in table_2.select('thead th')]\n",
    "\n",
    "# Extract the table rows\n",
    "rows_2 = []\n",
    "for tr in table_2.select('tbody tr'):\n",
    "    row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "    rows_2.append(row_2)\n",
    "\n",
    "# Check if there are any rows in the footer of the table\n",
    "footer_rows_2 = table_2.select('tfoot tr')\n",
    "if footer_rows_2:\n",
    "    # Extract the additional rows from the footer\n",
    "    additional_rows_2 = []\n",
    "    for tr in footer_rows_2:\n",
    "        row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "        additional_rows_2.append(row_2)\n",
    "\n",
    "    # Add the additional rows at the end of the extracted rows\n",
    "    rows_2.extend(additional_rows_2)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df_2 = pd.DataFrame(rows_2, columns=headers_2)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df_2.to_excel('Kg_C.xlsx', index=False)\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "\n",
    "# Function to convert columns to numeric except for specified columns\n",
    "def convert_columns_to_numeric(df, exclude_columns):\n",
    "    converted_df = df.copy()\n",
    "    for column in df.columns:\n",
    "        if column not in exclude_columns:\n",
    "            converted_df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "    return converted_df\n",
    "\n",
    "# List of Excel file names\n",
    "excel_files = [\"Kg_A.xlsx\", \"Kg_B.xlsx\", \"Kg_C.xlsx\"]\n",
    "\n",
    "# List of columns to exclude from conversion\n",
    "exclude_columns = [\"Count and Material\"]\n",
    "\n",
    "# Process each Excel file\n",
    "for file in excel_files:\n",
    "    # Read Excel file\n",
    "    df = pd.read_excel(file)\n",
    "    \n",
    "    # Convert columns to numeric\n",
    "    converted_df = convert_columns_to_numeric(df, exclude_columns)\n",
    "    \n",
    "    # Save the modified DataFrame back to the same Excel file\n",
    "    converted_df.to_excel(file, index=False)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# List of file names\n",
    "file_names = ['Kg_A.xlsx', 'Kg_B.xlsx', 'Kg_C.xlsx']\n",
    "\n",
    "# Initialize an empty DataFrame to store the concatenated data\n",
    "concatenated_data = pd.DataFrame()\n",
    "\n",
    "# Iterate over the file names and read each Excel file\n",
    "for file_name in file_names:\n",
    "    # Read the Excel file into a DataFrame\n",
    "    df = pd.read_excel(file_name)\n",
    "    \n",
    "    # Exclude the last row of the DataFrame\n",
    "    df = df.iloc[:-1]\n",
    "    \n",
    "    # Concatenate the data to the existing DataFrame\n",
    "    concatenated_data = pd.concat([concatenated_data, df], ignore_index=True)\n",
    "\n",
    "# Save the concatenated data to a new Excel file\n",
    "concatenated_data.to_excel('kg.xlsx', index=False)\n",
    "\n",
    "\n",
    "# Read the concatenated data from the Excel file\n",
    "concatenated_data = pd.read_excel('kg.xlsx')\n",
    "\n",
    "# Drop blank rows from the DataFrame\n",
    "concatenated_data = concatenated_data.dropna(how='all')\n",
    "\n",
    "# Save the updated data to the Excel file\n",
    "concatenated_data.to_excel('kg.xlsx', index=False)\n",
    "\n",
    "\n",
    "# Read the previous data from convt_kg.xlsx if it exists\n",
    "try:\n",
    "    previous_data = pd.read_excel('convt_kg.xlsx')\n",
    "except FileNotFoundError:\n",
    "    previous_data = pd.DataFrame()\n",
    "\n",
    "# Read the new data from kg.xlsx\n",
    "new_data = pd.read_excel('kg.xlsx')\n",
    "\n",
    "# Concatenate previous data and new data\n",
    "combined_data = pd.concat([previous_data, new_data], ignore_index=True)\n",
    "\n",
    "# Group the combined data by M/c No. and calculate the mean of AEF %\n",
    "grouped_data = combined_data.groupby('M/c No.').agg({'AEF %': 'mean','kg':'sum' }).reset_index()\n",
    "\n",
    "# Save the grouped data to convt_kg.xlsx\n",
    "grouped_data.to_excel('convt_kg.xlsx', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# trendline\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"http://192.168.168.216/premierJute/myPanel/trendcomparison\")\n",
    "\n",
    "wait = WebDriverWait(driver, 60)\n",
    "\n",
    "\n",
    "# Find the button using the provided relative XPath\n",
    "button = wait.until(EC.visibility_of_element_located((By.XPATH, \"//label[@id='lnum']\")))\n",
    "\n",
    "driver.set_window_size(1200, 800)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# Click on the button\n",
    "button.click()\n",
    "    \n",
    "# Execute JavaScript to unselect the checkbox\n",
    "driver.execute_script(\"document.querySelector(\\\"label[for='chk40']\\\").previousElementSibling.checked = false;\")\n",
    "\n",
    "\n",
    "# Execute JavaScript to select the first checkbox\n",
    "driver.execute_script(\"document.querySelector(\\\"label[for='chk9']\\\").click();\")\n",
    "\n",
    "# Wait for a brief moment\n",
    "time.sleep(2)\n",
    "\n",
    "# Execute JavaScript to select the second checkbox\n",
    "driver.execute_script(\"document.querySelector(\\\"label[for='chk69']\\\").click();\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extract the HTML content of the page\n",
    "html_code_2 = driver.page_source\n",
    "\n",
    "# Parse the HTML code with BeautifulSoup\n",
    "soup_2 = BeautifulSoup(html_code_2, 'html.parser')\n",
    "\n",
    "# Find the table element\n",
    "table_2 = soup_2.find('table', {'id': 'tblline'})\n",
    "\n",
    "# Extract the table headers\n",
    "headers_2 = [th.text.strip() for th in table_2.select('thead th')]\n",
    "\n",
    "# Extract the table rows\n",
    "rows_2 = []\n",
    "for tr in table_2.select('tbody tr'):\n",
    "    row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "    rows_2.append(row_2)\n",
    "\n",
    "# Check if there are any rows in the footer of the table\n",
    "footer_rows_2 = table_2.select('tfoot tr')\n",
    "if footer_rows_2:\n",
    "    # Extract the additional rows from the footer\n",
    "    additional_rows_2 = []\n",
    "    for tr in footer_rows_2:\n",
    "        row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "        additional_rows_2.append(row_2)\n",
    "\n",
    "    # Add the additional rows at the end of the extracted rows\n",
    "    rows_2.extend(additional_rows_2)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df_2 = pd.DataFrame(rows_2, columns=headers_2)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df_2.to_excel('trendline_1.xlsx', index=False)\n",
    "\n",
    "\n",
    "# Execute JavaScript to unselect the first checkbox\n",
    "driver.execute_script(\"document.querySelector(\\\"label[for='chk9']\\\").click();\")\n",
    "\n",
    "# Wait for a brief moment\n",
    "time.sleep(2)\n",
    "\n",
    "# Execute JavaScript to unselect the second checkbox\n",
    "driver.execute_script(\"document.querySelector(\\\"label[for='chk69']\\\").click();\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Execute JavaScript to select the first checkbox\n",
    "driver.execute_script(\"document.querySelector(\\\"label[for='chk130']\\\").click();\")\n",
    "\n",
    "# Wait for a brief moment\n",
    "time.sleep(2)\n",
    "\n",
    "# Execute JavaScript to select the second checkbox\n",
    "driver.execute_script(\"document.querySelector(\\\"label[for='chk32']\\\").click();\")\n",
    "\n",
    "\n",
    "# Extract the HTML content of the page\n",
    "html_code_2 = driver.page_source\n",
    "\n",
    "# Parse the HTML code with BeautifulSoup\n",
    "soup_2 = BeautifulSoup(html_code_2, 'html.parser')\n",
    "\n",
    "# Find the table element\n",
    "table_2 = soup_2.find('table', {'id': 'tblline'})\n",
    "\n",
    "# Extract the table headers\n",
    "headers_2 = [th.text.strip() for th in table_2.select('thead th')]\n",
    "\n",
    "# Extract the table rows\n",
    "rows_2 = []\n",
    "for tr in table_2.select('tbody tr'):\n",
    "    row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "    rows_2.append(row_2)\n",
    "\n",
    "# Check if there are any rows in the footer of the table\n",
    "footer_rows_2 = table_2.select('tfoot tr')\n",
    "if footer_rows_2:\n",
    "    # Extract the additional rows from the footer\n",
    "    additional_rows_2 = []\n",
    "    for tr in footer_rows_2:\n",
    "        row_2 = [td.text.strip() for td in tr.select('td')]\n",
    "        additional_rows_2.append(row_2)\n",
    "\n",
    "    # Add the additional rows at the end of the extracted rows\n",
    "    rows_2.extend(additional_rows_2)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df_2 = pd.DataFrame(rows_2, columns=headers_2)\n",
    "\n",
    "# Write the DataFrame to an Excel file\n",
    "df_2.to_excel('trendline_2.xlsx', index=False)\n",
    "\n",
    "\n",
    "# Function to convert columns to numeric except for specified columns\n",
    "def convert_columns_to_numeric(df, exclude_columns):\n",
    "    converted_df = df.copy()\n",
    "    for column in df.columns:\n",
    "        if column not in exclude_columns:\n",
    "            converted_df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "    return converted_df\n",
    "\n",
    "# List of Excel file names\n",
    "excel_files = [\"trendline_1.xlsx\",\"trendline_2.xlsx\"]\n",
    "\n",
    "\n",
    "\n",
    "# List of columns to exclude from conversion\n",
    "exclude_columns = [\"Period\"]\n",
    "\n",
    "# Process each Excel file\n",
    "for file in excel_files:\n",
    "    # Read Excel file\n",
    "    df = pd.read_excel(file)\n",
    "    \n",
    "    # Convert columns to numeric\n",
    "    converted_df = convert_columns_to_numeric(df, exclude_columns)\n",
    "    \n",
    "    # Save the modified DataFrame back to the same Excel file\n",
    "    converted_df.to_excel(file, index=False)\n",
    "\n",
    "\n",
    "time.sleep(10)\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# file manipulation\n",
    "\n",
    "\n",
    "def is_cell_in_merged_range(cell, merged_ranges):\n",
    "    \"\"\"\n",
    "    Check if the given cell falls within any of the merged ranges.\n",
    "    \"\"\"\n",
    "    for merged_range in merged_ranges:\n",
    "        if cell.coordinate in merged_range:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def concatenate_trend_data(filename, period_col, data_col, dest_col):\n",
    "    \"\"\"\n",
    "    Concatenate data from the trendline file to the specified columns in the Trends sheet.\n",
    "    \"\"\"\n",
    "    trendline_data = pd.read_excel(filename)\n",
    "    workbook = load_workbook('UltimoJJ analysis report.xlsx')\n",
    "    sheet = workbook['Trends']\n",
    "    \n",
    "    # Get merged ranges in the sheet\n",
    "    merged_ranges = sheet.merged_cells.ranges\n",
    "    \n",
    "    # Find the first empty row after the 4th row\n",
    "    first_blank_row_dest = 4\n",
    "    while sheet.cell(row=first_blank_row_dest, column=dest_col).value is not None:\n",
    "        first_blank_row_dest += 1\n",
    "    \n",
    "    # Write the \"Period\" column to the destination column starting from the first blank row\n",
    "    for index, period in enumerate(trendline_data[period_col]):\n",
    "        sheet.cell(row=first_blank_row_dest+index, column=dest_col).value = period\n",
    "    \n",
    "    # Write the data column to the destination column starting from the first blank row\n",
    "    for index, value in enumerate(trendline_data[data_col]):\n",
    "        current_row = first_blank_row_dest + index\n",
    "        cell = sheet.cell(row=current_row, column=dest_col + 1)  # Adjusted to start from 10 columns after dest_col\n",
    "        if not is_cell_in_merged_range(cell, merged_ranges):\n",
    "            cell.value = value\n",
    "    \n",
    "    # Save the updated workbook\n",
    "    workbook.save('UltimoJJ analysis report.xlsx')\n",
    "\n",
    "# Concatenate data from trendline_1.xlsx to columns B and C in the Trends sheet\n",
    "concatenate_trend_data('trendline_1.xlsx', 'Period', 'min/doff( 1 )', 2)\n",
    "\n",
    "# Concatenate data from trendline_1.xlsx to columns D and E in the Trends sheet\n",
    "concatenate_trend_data('trendline_1.xlsx', 'Period', 'stop %( 1 )', 5)\n",
    "\n",
    "# Concatenate data from trendline_2.xlsx to columns F and G in the Trends sheet\n",
    "concatenate_trend_data('trendline_2.xlsx', 'Period', '% loss idle    ( 1 )', 8)\n",
    "\n",
    "# Concatenate data from trendline_2.xlsx to columns H and I in the Trends sheet\n",
    "concatenate_trend_data('trendline_2.xlsx', 'Period', 'ebI/100sh( 1 )', 11)\n",
    "\n",
    "\n",
    "# Load the conv_break.xlsx file\n",
    "conv_break_workbook = openpyxl.load_workbook('convt_break.xlsx')\n",
    "conv_break_sheet = conv_break_workbook.active\n",
    "\n",
    "# Load the UltimoJJ analysis report.xlsx file\n",
    "ultimojj_workbook = openpyxl.load_workbook('UltimoJJ analysis report.xlsx')\n",
    "ultimojj_sheet = ultimojj_workbook['Breakage']\n",
    "\n",
    "# Clear existing data in the UltimoJJ analysis report.xlsx file\n",
    "ultimojj_sheet.delete_rows(1, ultimojj_sheet.max_row)\n",
    "\n",
    "# Copy data from conv_break.xlsx to UltimoJJ analysis report.xlsx\n",
    "for row in conv_break_sheet.iter_rows(values_only=True):\n",
    "    ultimojj_sheet.append(row)\n",
    "\n",
    "# Save the updated UltimoJJ analysis report.xlsx file\n",
    "ultimojj_workbook.save('UltimoJJ analysis report.xlsx')\n",
    "\n",
    "\n",
    "# Load the convt_kg.xlsx file\n",
    "convt_kg_workbook = openpyxl.load_workbook('convt_kg.xlsx')\n",
    "convt_kg_sheet = convt_kg_workbook.active\n",
    "\n",
    "# Load the UltimoJJ analysis report.xlsx file\n",
    "ultimojj_workbook = openpyxl.load_workbook('UltimoJJ analysis report.xlsx')\n",
    "ultimojj_sheet = ultimojj_workbook['Kg']\n",
    "\n",
    "# Clear existing data in the \"AEF %\" column (column D) in the \"Kg\" sheet\n",
    "for row in ultimojj_sheet.iter_rows(min_row=2, min_col=4, max_col=4):\n",
    "    for cell in row:\n",
    "        cell.value = None\n",
    "\n",
    "# Copy \"AEF %\" data from convt_kg.xlsx to UltimoJJ analysis report.xlsx\n",
    "for row in convt_kg_sheet.iter_rows(min_row=2, min_col=2, max_col=2):\n",
    "    for cell in row:\n",
    "        ultimojj_sheet.cell(row=cell.row, column=4).value = cell.value\n",
    "\n",
    "# Save the updated UltimoJJ analysis report.xlsx file\n",
    "ultimojj_workbook.save('UltimoJJ analysis report.xlsx')\n",
    "\n",
    "\n",
    "# Load the convt_kg.xlsx file\n",
    "convt_kg_workbook = openpyxl.load_workbook('convt_kg.xlsx')\n",
    "convt_kg_sheet = convt_kg_workbook.active\n",
    "\n",
    "# Load the UltimoJJ analysis report.xlsx file\n",
    "ultimojj_workbook = openpyxl.load_workbook('UltimoJJ analysis report.xlsx')\n",
    "ultimojj_sheet = ultimojj_workbook['Kg']\n",
    "\n",
    "# Clear existing data in the \"kg\" column (column D) in the \"Kg\" sheet\n",
    "for row in ultimojj_sheet.iter_rows(min_row=2, min_col=8, max_col=8):\n",
    "    for cell in row:\n",
    "        cell.value = None\n",
    "\n",
    "# Copy \"AEF %\" data from convt_kg.xlsx to UltimoJJ analysis report.xlsx\n",
    "for row in convt_kg_sheet.iter_rows(min_row=2, min_col=3, max_col=3):\n",
    "    for cell in row:\n",
    "        ultimojj_sheet.cell(row=cell.row, column=8).value = cell.value\n",
    "\n",
    "# Save the updated UltimoJJ analysis report.xlsx file\n",
    "ultimojj_workbook.save('UltimoJJ analysis report.xlsx')\n",
    "\n",
    "\n",
    "\n",
    "# Load kg_A.xlsx file\n",
    "kg_a_workbook = openpyxl.load_workbook('kg_A.xlsx')\n",
    "kg_a_sheet = kg_a_workbook.active\n",
    "\n",
    "# Load kg_B.xlsx file\n",
    "kg_b_workbook = openpyxl.load_workbook('kg_B.xlsx')\n",
    "kg_b_sheet = kg_b_workbook.active\n",
    "\n",
    "# Load kg_C.xlsx file\n",
    "kg_c_workbook = openpyxl.load_workbook('kg_C.xlsx')\n",
    "kg_c_sheet = kg_c_workbook.active\n",
    "\n",
    "# Load UltimoJJ analysis report.xlsx file\n",
    "ultimojj_workbook = openpyxl.load_workbook('UltimoJJ analysis report.xlsx')\n",
    "summary_sheet = ultimojj_workbook['Summary']\n",
    "\n",
    "# Get the sum of \"kg\" column in kg_A.xlsx file\n",
    "kg_a_sum = sum(cell.value for cell in kg_a_sheet['G'][3:-1])\n",
    "\n",
    "# Get the sum of \"kg\" column in kg_B.xlsx file\n",
    "kg_b_sum = sum(cell.value for cell in kg_b_sheet['G'][3:-1])\n",
    "\n",
    "# Get the sum of \"kg\" column in kg_C.xlsx file\n",
    "kg_c_sum = sum(cell.value for cell in kg_c_sheet['G'][3:-1])\n",
    "\n",
    "# Write the sums to the respective cells in the Summary sheet\n",
    "summary_sheet['C26'] = kg_a_sum\n",
    "summary_sheet['F26'] = kg_b_sum\n",
    "summary_sheet['I26'] = kg_c_sum\n",
    "\n",
    "# Save the updated UltimoJJ analysis report.xlsx file\n",
    "ultimojj_workbook.save('UltimoJJ analysis report.xlsx')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def perform_calculations(manager_file):\n",
    "    if not os.path.isfile(manager_file):\n",
    "        return None\n",
    "\n",
    "    # Rest of the calculation code...\n",
    "    # (Remaining code from the previous example)\n",
    "\n",
    "# List of manager files\n",
    "manager_files = ['manager_A.xlsx', 'manager_B.xlsx', 'manager_C.xlsx']\n",
    "\n",
    "# Results dictionary to store the sum results\n",
    "results = {}\n",
    "\n",
    "# Perform calculations for each manager file\n",
    "for manager_file in manager_files:\n",
    "    sum_result = perform_calculations(manager_file)\n",
    "    if sum_result is not None:\n",
    "        results[manager_file] = sum_result\n",
    "\n",
    "# Load the \"UltimoJJ analysis report.xlsx\" file\n",
    "workbook = load_workbook('UltimoJJ analysis report.xlsx')\n",
    "\n",
    "# Get the \"Summary\" sheet\n",
    "summary_sheet = workbook['Summary']\n",
    "\n",
    "# Write the sum results to the appropriate cells in the Summary sheet\n",
    "for i, manager_file in enumerate(manager_files):\n",
    "    cell = chr(ord('C') + 3*i) + '25'  # Calculate the cell address dynamically\n",
    "    sum_result = results.get(manager_file)\n",
    "    if sum_result is not None:\n",
    "        summary_sheet[cell] = sum_result\n",
    "\n",
    "# Save the modified workbook\n",
    "workbook.save('UltimoJJ analysis report.xlsx')\n",
    "\n",
    "# Print the results\n",
    "for manager_file, sum_result in results.items():\n",
    "    print(f\"{manager_file} Sum Result:\", sum_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f375d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from openpyxl.chart import BarChart, Reference\n",
    "\n",
    "# Load the workbook\n",
    "workbook = openpyxl.load_workbook('UltimoJJ analysis report.xlsx')\n",
    "\n",
    "# Select the \"Summary\" sheet\n",
    "sheet = workbook['Summary']\n",
    "\n",
    "# Define the data range for the chart\n",
    "data_range = 'Summary!Z5:Z8'\n",
    "data = Reference(sheet, range_string=data_range)\n",
    "\n",
    "# Define the x-axis labels range\n",
    "labels_range = 'Summary!Y6:Y8'\n",
    "labels = Reference(sheet, range_string=labels_range)\n",
    "\n",
    "# Create a new bar chart\n",
    "chart = BarChart()\n",
    "\n",
    "# Add the data to the chart\n",
    "chart.add_data(data, titles_from_data=True)\n",
    "\n",
    "# Set the chart title\n",
    "chart.title = \"Avg number of idle spindle per frame\"\n",
    "\n",
    "# Set the x-axis labels\n",
    "chart.set_categories(labels)\n",
    "\n",
    "# Set the x-axis title\n",
    "chart.x_axis.title = \"Categories\"\n",
    "\n",
    "# Set the y-axis title\n",
    "chart.y_axis.title = \"Values\"\n",
    "\n",
    "# Add the chart to the sheet\n",
    "sheet.add_chart(chart, \"B35\")\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save('UltimoJJ analysis report.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f12b6ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from openpyxl.chart import BarChart, Reference\n",
    "\n",
    "# Load the workbook\n",
    "workbook = openpyxl.load_workbook('UltimoJJ analysis report.xlsx')\n",
    "\n",
    "# Select the \"Summary\" sheet\n",
    "sheet = workbook['Summary']\n",
    "\n",
    "# Define the data range for the chart\n",
    "data_range = 'Summary!AB5:AB8'\n",
    "data = Reference(sheet, range_string=data_range)\n",
    "\n",
    "# Define the x-axis labels range\n",
    "labels_range = 'Summary!AA6:AA8'\n",
    "labels = Reference(sheet, range_string=labels_range)\n",
    "\n",
    "# Create a new bar chart\n",
    "chart = BarChart()\n",
    "\n",
    "# Add the data to the chart\n",
    "chart.add_data(data, titles_from_data=True)\n",
    "\n",
    "# Set the chart title\n",
    "chart.title = \"Avg number of doffs per frame\"\n",
    "\n",
    "# Set the x-axis labels\n",
    "chart.set_categories(labels)\n",
    "\n",
    "# Set the x-axis title\n",
    "chart.x_axis.title = \"Categories\"\n",
    "\n",
    "# Set the y-axis title\n",
    "chart.y_axis.title = \"Values\"\n",
    "\n",
    "# Add the chart to the sheet\n",
    "sheet.add_chart(chart, \"F35\")\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save('UltimoJJ analysis report.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8be498ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from openpyxl.chart import BarChart, Reference\n",
    "\n",
    "# Load the workbook\n",
    "workbook = openpyxl.load_workbook('UltimoJJ analysis report.xlsx')\n",
    "\n",
    "# Select the \"Summary\" sheet\n",
    "sheet = workbook['Summary']\n",
    "\n",
    "# Define the data range for the chart\n",
    "data_range = 'Summary!AD5:AD8'\n",
    "data = Reference(sheet, range_string=data_range)\n",
    "\n",
    "# Define the x-axis labels range\n",
    "labels_range = 'Summary!AC6:AC8'\n",
    "labels = Reference(sheet, range_string=labels_range)\n",
    "\n",
    "# Create a new bar chart\n",
    "chart = BarChart()\n",
    "\n",
    "# Add the data to the chart\n",
    "chart.add_data(data, titles_from_data=True)\n",
    "\n",
    "# Set the chart title\n",
    "chart.title = \"Avg doff changeover minutes\"\n",
    "\n",
    "# Set the x-axis labels\n",
    "chart.set_categories(labels)\n",
    "\n",
    "# Set the x-axis title\n",
    "chart.x_axis.title = \"Categories\"\n",
    "\n",
    "# Set the y-axis title\n",
    "chart.y_axis.title = \"Values\"\n",
    "\n",
    "# Add the chart to the sheet\n",
    "sheet.add_chart(chart, \"B53\")\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save('UltimoJJ analysis report.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d53fd01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from openpyxl.chart import BarChart, Reference\n",
    "\n",
    "# Load the workbook\n",
    "workbook = openpyxl.load_workbook('UltimoJJ analysis report.xlsx')\n",
    "\n",
    "# Select the \"Summary\" sheet\n",
    "sheet = workbook['Summary']\n",
    "\n",
    "# Define the data range for the chart\n",
    "data_range = 'Summary!AF5:AF8'\n",
    "data = Reference(sheet, range_string=data_range)\n",
    "\n",
    "# Define the x-axis labels range\n",
    "labels_range = 'Summary!AE6:AE8'\n",
    "labels = Reference(sheet, range_string=labels_range)\n",
    "\n",
    "# Create a new bar chart\n",
    "chart = BarChart()\n",
    "\n",
    "# Add the data to the chart\n",
    "chart.add_data(data, titles_from_data=True)\n",
    "\n",
    "# Set the chart title\n",
    "chart.title = \"Avg number of breakage per frame\"\n",
    "\n",
    "# Set the x-axis labels\n",
    "chart.set_categories(labels)\n",
    "\n",
    "# Set the x-axis title\n",
    "chart.x_axis.title = \"Categories\"\n",
    "\n",
    "# Set the y-axis title\n",
    "chart.y_axis.title = \"Values\"\n",
    "\n",
    "# Add the chart to the sheet\n",
    "sheet.add_chart(chart, \"F53\")\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save('UltimoJJ analysis report.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "95617cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from openpyxl.chart import BarChart, Reference\n",
    "\n",
    "# Load the workbook\n",
    "workbook = openpyxl.load_workbook('UltimoJJ analysis report.xlsx')\n",
    "\n",
    "# Select the \"Summary\" sheet\n",
    "sheet = workbook['Summary']\n",
    "\n",
    "# Define the data range for the chart\n",
    "data_range = 'Summary!AH5:AH8'\n",
    "data = Reference(sheet, range_string=data_range)\n",
    "\n",
    "# Define the x-axis labels range\n",
    "labels_range = 'Summary!AG6:AG8'\n",
    "labels = Reference(sheet, range_string=labels_range)\n",
    "\n",
    "# Create a new bar chart\n",
    "chart = BarChart()\n",
    "\n",
    "# Add the data to the chart\n",
    "chart.add_data(data, titles_from_data=True)\n",
    "\n",
    "# Set the chart title\n",
    "chart.title = \"Avg stop minutes per frame\"\n",
    "\n",
    "# Set the x-axis labels\n",
    "chart.set_categories(labels)\n",
    "\n",
    "# Set the x-axis title\n",
    "chart.x_axis.title = \"Categories\"\n",
    "\n",
    "# Set the y-axis title\n",
    "chart.y_axis.title = \"Values\"\n",
    "\n",
    "# Add the chart to the sheet\n",
    "sheet.add_chart(chart, \"B70\")\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save('UltimoJJ analysis report.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "038cd8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from openpyxl.chart import BarChart, Reference\n",
    "\n",
    "# Load the workbook\n",
    "workbook = openpyxl.load_workbook('UltimoJJ analysis report.xlsx')\n",
    "\n",
    "# Select the \"Summary\" sheet\n",
    "sheet = workbook['Summary']\n",
    "\n",
    "# Define the data range for the chart (from the \"Breakage\" sheet)\n",
    "breakage_sheet = workbook['Breakage']\n",
    "data_range = 'Breakage!C2:C33'\n",
    "data = Reference(breakage_sheet, range_string=data_range)\n",
    "\n",
    "# Define the x-axis labels range (from the \"Breakage\" sheet)\n",
    "labels_range = 'Breakage!A2:A33'\n",
    "labels = Reference(breakage_sheet, range_string=labels_range)\n",
    "\n",
    "# Create a new bar chart\n",
    "chart = BarChart()\n",
    "\n",
    "# Add the data to the chart\n",
    "chart.add_data(data, titles_from_data=True)\n",
    "\n",
    "# Set the chart title\n",
    "chart.title = \"Frame wise ends breakage \"\n",
    "\n",
    "# Set the x-axis labels\n",
    "chart.set_categories(labels)\n",
    "\n",
    "# Set the x-axis title\n",
    "chart.x_axis.title = \"Categories\"\n",
    "\n",
    "# Set the y-axis title\n",
    "chart.y_axis.title = \"Values\"\n",
    "\n",
    "# Add the chart to the \"Summary\" sheet\n",
    "sheet.add_chart(chart, \"B87\")\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save('UltimoJJ analysis report.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d688593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from openpyxl.chart import BarChart, Reference\n",
    "\n",
    "# Load the workbook\n",
    "workbook = openpyxl.load_workbook('UltimoJJ analysis report.xlsx')\n",
    "\n",
    "# Select the \"Summary\" sheet\n",
    "sheet = workbook['Summary']\n",
    "\n",
    "# Define the data range for the chart (from the \"Breakage\" sheet)\n",
    "breakage_sheet = workbook['Kg']\n",
    "data_range = 'Kg!J3:J34'\n",
    "data = Reference(breakage_sheet, range_string=data_range)\n",
    "\n",
    "# Define the x-axis labels range (from the \"Breakage\" sheet)\n",
    "labels_range = 'Kg!B3:B34'\n",
    "labels = Reference(breakage_sheet, range_string=labels_range)\n",
    "\n",
    "# Create a new bar chart\n",
    "chart = BarChart()\n",
    "\n",
    "# Add the data to the chart\n",
    "chart.add_data(data, titles_from_data=True)\n",
    "\n",
    "# Set the chart title\n",
    "chart.title = \"Frame wise converted production\"\n",
    "\n",
    "# Set the x-axis labels\n",
    "chart.set_categories(labels)\n",
    "\n",
    "# Set the x-axis title\n",
    "chart.x_axis.title = \"Categories\"\n",
    "\n",
    "# Set the y-axis title\n",
    "chart.y_axis.title = \"Values\"\n",
    "\n",
    "# Add the chart to the \"Summary\" sheet\n",
    "sheet.add_chart(chart, \"B107\")\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save('UltimoJJ analysis report.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e6146291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from openpyxl.chart import BarChart, Reference\n",
    "\n",
    "# Load the workbook\n",
    "workbook = openpyxl.load_workbook('UltimoJJ analysis report.xlsx')\n",
    "\n",
    "# Select the \"Summary\" sheet\n",
    "sheet = workbook['Summary']\n",
    "\n",
    "# Define the data range for the chart (from the \"Breakage\" sheet)\n",
    "breakage_sheet = workbook['Kg']\n",
    "data_range = 'Kg!D3:D34'\n",
    "data = Reference(breakage_sheet, range_string=data_range)\n",
    "\n",
    "# Define the x-axis labels range (from the \"Breakage\" sheet)\n",
    "labels_range = 'Kg!B3:B34'\n",
    "labels = Reference(breakage_sheet, range_string=labels_range)\n",
    "\n",
    "# Create a new bar chart\n",
    "chart = BarChart()\n",
    "\n",
    "# Add the data to the chart\n",
    "chart.add_data(data, titles_from_data=True)\n",
    "\n",
    "# Set the chart title\n",
    "chart.title = \"Frame wise efficiency as on\"\n",
    "\n",
    "# Set the x-axis labels\n",
    "chart.set_categories(labels)\n",
    "\n",
    "# Set the x-axis title\n",
    "chart.x_axis.title = \"Categories\"\n",
    "\n",
    "# Set the y-axis title\n",
    "chart.y_axis.title = \"Values\"\n",
    "\n",
    "# Add the chart to the \"Summary\" sheet\n",
    "sheet.add_chart(chart, \"B125\")\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save('UltimoJJ analysis report.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a93f018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from openpyxl.chart import BarChart, Reference\n",
    "\n",
    "# Load the workbook\n",
    "workbook = openpyxl.load_workbook('UltimoJJ analysis report.xlsx')\n",
    "\n",
    "# Select the \"Summary\" sheet\n",
    "sheet = workbook['Summary']\n",
    "\n",
    "# Define the data range for the chart (from the \"Breakage\" sheet)\n",
    "breakage_sheet = workbook['Trends']\n",
    "last_row = breakage_sheet.max_row\n",
    "data_range = f'Trends!C4:C{last_row}'\n",
    "data = Reference(breakage_sheet, range_string=data_range)\n",
    "\n",
    "# Define the x-axis labels range (from the \"Breakage\" sheet)\n",
    "labels_range = f'Trends!B4:B{last_row}'\n",
    "labels = Reference(breakage_sheet, range_string=labels_range)\n",
    "\n",
    "# Create a new bar chart\n",
    "chart = BarChart()\n",
    "\n",
    "# Add the data to the chart\n",
    "chart.add_data(data, titles_from_data=True)\n",
    "\n",
    "# Set the chart title\n",
    "chart.title = \"avg min/doff\"\n",
    "\n",
    "# Set the x-axis labels\n",
    "chart.set_categories(labels)\n",
    "\n",
    "# Set the x-axis title\n",
    "chart.x_axis.title = \"Categories\"\n",
    "\n",
    "# Set the y-axis title\n",
    "chart.y_axis.title = \"Values\"\n",
    "\n",
    "# Add the chart to the \"Summary\" sheet\n",
    "sheet.add_chart(chart, \"K7\")\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save('UltimoJJ analysis report.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6a23f81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from openpyxl.chart import BarChart, Reference\n",
    "\n",
    "# Load the workbook\n",
    "workbook = openpyxl.load_workbook('UltimoJJ analysis report.xlsx')\n",
    "\n",
    "# Select the \"Summary\" sheet\n",
    "sheet = workbook['Summary']\n",
    "\n",
    "# Define the data range for the chart (from the \"Breakage\" sheet)\n",
    "breakage_sheet = workbook['Trends']\n",
    "last_row = breakage_sheet.max_row\n",
    "data_range = f'Trends!F4:F{last_row}'\n",
    "data = Reference(breakage_sheet, range_string=data_range)\n",
    "\n",
    "# Define the x-axis labels range (from the \"Breakage\" sheet)\n",
    "labels_range = f'Trends!E4:E{last_row}'\n",
    "labels = Reference(breakage_sheet, range_string=labels_range)\n",
    "\n",
    "# Create a new bar chart\n",
    "chart = BarChart()\n",
    "\n",
    "# Add the data to the chart\n",
    "chart.add_data(data, titles_from_data=True)\n",
    "\n",
    "# Set the chart title\n",
    "chart.title = \"Stop %\"\n",
    "\n",
    "# Set the x-axis labels\n",
    "chart.set_categories(labels)\n",
    "\n",
    "# Set the x-axis title\n",
    "chart.x_axis.title = \"Categories\"\n",
    "\n",
    "# Set the y-axis title\n",
    "chart.y_axis.title = \"Values\"\n",
    "\n",
    "# Add the chart to the \"Summary\" sheet\n",
    "sheet.add_chart(chart, \"K19\")\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save('UltimoJJ analysis report.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0fe8955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from openpyxl.chart import BarChart, Reference\n",
    "\n",
    "# Load the workbook\n",
    "workbook = openpyxl.load_workbook('UltimoJJ analysis report.xlsx')\n",
    "\n",
    "# Select the \"Summary\" sheet\n",
    "sheet = workbook['Summary']\n",
    "\n",
    "# Define the data range for the chart (from the \"Breakage\" sheet)\n",
    "breakage_sheet = workbook['Trends']\n",
    "last_row = breakage_sheet.max_row\n",
    "data_range = f'Trends!I4:I{last_row}'\n",
    "data = Reference(breakage_sheet, range_string=data_range)\n",
    "\n",
    "# Define the x-axis labels range (from the \"Breakage\" sheet)\n",
    "labels_range = f'Trends!H4:H{last_row}'\n",
    "labels = Reference(breakage_sheet, range_string=labels_range)\n",
    "\n",
    "# Create a new bar chart\n",
    "chart = BarChart()\n",
    "\n",
    "# Add the data to the chart\n",
    "chart.add_data(data, titles_from_data=True)\n",
    "\n",
    "# Set the chart title\n",
    "chart.title = \"Idle %\"\n",
    "\n",
    "# Set the x-axis labels\n",
    "chart.set_categories(labels)\n",
    "\n",
    "# Set the x-axis title\n",
    "chart.x_axis.title = \"Categories\"\n",
    "\n",
    "# Set the y-axis title\n",
    "chart.y_axis.title = \"Values\"\n",
    "\n",
    "# Add the chart to the \"Summary\" sheet\n",
    "sheet.add_chart(chart, \"K32\")\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save('UltimoJJ analysis report.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "46fe49b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from openpyxl.chart import BarChart, Reference\n",
    "\n",
    "# Load the workbook\n",
    "workbook = openpyxl.load_workbook('UltimoJJ analysis report.xlsx')\n",
    "\n",
    "# Select the \"Summary\" sheet\n",
    "sheet = workbook['Summary']\n",
    "\n",
    "# Define the data range for the chart (from the \"Breakage\" sheet)\n",
    "breakage_sheet = workbook['Trends']\n",
    "last_row = breakage_sheet.max_row\n",
    "data_range = f'Trends!L4:L{last_row}'\n",
    "data = Reference(breakage_sheet, range_string=data_range)\n",
    "\n",
    "# Define the x-axis labels range (from the \"Breakage\" sheet)\n",
    "labels_range = f'Trends!K4:K{last_row}'\n",
    "labels = Reference(breakage_sheet, range_string=labels_range)\n",
    "\n",
    "# Create a new bar chart\n",
    "chart = BarChart()\n",
    "\n",
    "# Add the data to the chart\n",
    "chart.add_data(data, titles_from_data=True)\n",
    "\n",
    "# Set the chart title\n",
    "chart.title = \"Eb/100spdle/hour\"\n",
    "\n",
    "# Set the x-axis labels\n",
    "chart.set_categories(labels)\n",
    "\n",
    "# Set the x-axis title\n",
    "chart.x_axis.title = \"Categories\"\n",
    "\n",
    "# Set the y-axis title\n",
    "chart.y_axis.title = \"Values\"\n",
    "\n",
    "# Add the chart to the \"Summary\" sheet\n",
    "sheet.add_chart(chart, \"K46\")\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save('UltimoJJ analysis report.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0690d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
